{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d4c170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5575587a614d73850f1b9cd2e04a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: ['conv_in.weight', 'conv_in.bias', 'time_embedding.linear_1.weight', 'time_embedding.linear_1.bias', 'time_embedding.linear_2.weight', 'time_embedding.linear_2.bias', 'down_blocks.0.attentions.0.norm.weight', 'down_blocks.0.attentions.0.norm.bias', 'down_blocks.0.attentions.0.proj_in.weight', 'down_blocks.0.attentions.0.proj_in.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.norm1.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.norm1.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.norm2.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.norm2.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.norm3.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.norm3.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.bias', 'down_blocks.0.attentions.0.proj_out.weight', 'down_blocks.0.attentions.0.proj_out.bias', 'down_blocks.0.attentions.1.norm.weight', 'down_blocks.0.attentions.1.norm.bias', 'down_blocks.0.attentions.1.proj_in.weight', 'down_blocks.0.attentions.1.proj_in.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.norm1.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.norm1.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.norm2.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.norm2.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.norm3.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.norm3.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.bias', 'down_blocks.0.attentions.1.proj_out.weight', 'down_blocks.0.attentions.1.proj_out.bias', 'down_blocks.0.resnets.0.norm1.weight', 'down_blocks.0.resnets.0.norm1.bias', 'down_blocks.0.resnets.0.conv1.weight', 'down_blocks.0.resnets.0.conv1.bias', 'down_blocks.0.resnets.0.time_emb_proj.weight', 'down_blocks.0.resnets.0.time_emb_proj.bias', 'down_blocks.0.resnets.0.norm2.weight', 'down_blocks.0.resnets.0.norm2.bias', 'down_blocks.0.resnets.0.conv2.weight', 'down_blocks.0.resnets.0.conv2.bias', 'down_blocks.0.resnets.1.norm1.weight', 'down_blocks.0.resnets.1.norm1.bias', 'down_blocks.0.resnets.1.conv1.weight', 'down_blocks.0.resnets.1.conv1.bias', 'down_blocks.0.resnets.1.time_emb_proj.weight', 'down_blocks.0.resnets.1.time_emb_proj.bias', 'down_blocks.0.resnets.1.norm2.weight', 'down_blocks.0.resnets.1.norm2.bias', 'down_blocks.0.resnets.1.conv2.weight', 'down_blocks.0.resnets.1.conv2.bias', 'down_blocks.0.downsamplers.0.conv.weight', 'down_blocks.0.downsamplers.0.conv.bias', 'down_blocks.1.attentions.0.norm.weight', 'down_blocks.1.attentions.0.norm.bias', 'down_blocks.1.attentions.0.proj_in.weight', 'down_blocks.1.attentions.0.proj_in.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.norm1.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.norm1.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.norm2.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.norm2.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.norm3.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.norm3.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias', 'down_blocks.1.attentions.0.proj_out.weight', 'down_blocks.1.attentions.0.proj_out.bias', 'down_blocks.1.attentions.1.norm.weight', 'down_blocks.1.attentions.1.norm.bias', 'down_blocks.1.attentions.1.proj_in.weight', 'down_blocks.1.attentions.1.proj_in.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.norm1.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.norm1.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.norm2.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.norm2.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.norm3.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.norm3.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias', 'down_blocks.1.attentions.1.proj_out.weight', 'down_blocks.1.attentions.1.proj_out.bias', 'down_blocks.1.resnets.0.norm1.weight', 'down_blocks.1.resnets.0.norm1.bias', 'down_blocks.1.resnets.0.conv1.weight', 'down_blocks.1.resnets.0.conv1.bias', 'down_blocks.1.resnets.0.time_emb_proj.weight', 'down_blocks.1.resnets.0.time_emb_proj.bias', 'down_blocks.1.resnets.0.norm2.weight', 'down_blocks.1.resnets.0.norm2.bias', 'down_blocks.1.resnets.0.conv2.weight', 'down_blocks.1.resnets.0.conv2.bias', 'down_blocks.1.resnets.0.conv_shortcut.weight', 'down_blocks.1.resnets.0.conv_shortcut.bias', 'down_blocks.1.resnets.1.norm1.weight', 'down_blocks.1.resnets.1.norm1.bias', 'down_blocks.1.resnets.1.conv1.weight', 'down_blocks.1.resnets.1.conv1.bias', 'down_blocks.1.resnets.1.time_emb_proj.weight', 'down_blocks.1.resnets.1.time_emb_proj.bias', 'down_blocks.1.resnets.1.norm2.weight', 'down_blocks.1.resnets.1.norm2.bias', 'down_blocks.1.resnets.1.conv2.weight', 'down_blocks.1.resnets.1.conv2.bias', 'down_blocks.1.downsamplers.0.conv.weight', 'down_blocks.1.downsamplers.0.conv.bias', 'down_blocks.2.attentions.0.norm.weight', 'down_blocks.2.attentions.0.norm.bias', 'down_blocks.2.attentions.0.proj_in.weight', 'down_blocks.2.attentions.0.proj_in.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.norm1.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.norm1.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.norm2.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.norm2.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.norm3.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.norm3.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias', 'down_blocks.2.attentions.0.proj_out.weight', 'down_blocks.2.attentions.0.proj_out.bias', 'down_blocks.2.attentions.1.norm.weight', 'down_blocks.2.attentions.1.norm.bias', 'down_blocks.2.attentions.1.proj_in.weight', 'down_blocks.2.attentions.1.proj_in.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.norm1.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.norm1.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.norm2.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.norm2.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.norm3.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.norm3.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias', 'down_blocks.2.attentions.1.proj_out.weight', 'down_blocks.2.attentions.1.proj_out.bias', 'down_blocks.2.resnets.0.norm1.weight', 'down_blocks.2.resnets.0.norm1.bias', 'down_blocks.2.resnets.0.conv1.weight', 'down_blocks.2.resnets.0.conv1.bias', 'down_blocks.2.resnets.0.time_emb_proj.weight', 'down_blocks.2.resnets.0.time_emb_proj.bias', 'down_blocks.2.resnets.0.norm2.weight', 'down_blocks.2.resnets.0.norm2.bias', 'down_blocks.2.resnets.0.conv2.weight', 'down_blocks.2.resnets.0.conv2.bias', 'down_blocks.2.resnets.0.conv_shortcut.weight', 'down_blocks.2.resnets.0.conv_shortcut.bias', 'down_blocks.2.resnets.1.norm1.weight', 'down_blocks.2.resnets.1.norm1.bias', 'down_blocks.2.resnets.1.conv1.weight', 'down_blocks.2.resnets.1.conv1.bias', 'down_blocks.2.resnets.1.time_emb_proj.weight', 'down_blocks.2.resnets.1.time_emb_proj.bias', 'down_blocks.2.resnets.1.norm2.weight', 'down_blocks.2.resnets.1.norm2.bias', 'down_blocks.2.resnets.1.conv2.weight', 'down_blocks.2.resnets.1.conv2.bias', 'down_blocks.2.downsamplers.0.conv.weight', 'down_blocks.2.downsamplers.0.conv.bias', 'down_blocks.3.resnets.0.norm1.weight', 'down_blocks.3.resnets.0.norm1.bias', 'down_blocks.3.resnets.0.conv1.weight', 'down_blocks.3.resnets.0.conv1.bias', 'down_blocks.3.resnets.0.time_emb_proj.weight', 'down_blocks.3.resnets.0.time_emb_proj.bias', 'down_blocks.3.resnets.0.norm2.weight', 'down_blocks.3.resnets.0.norm2.bias', 'down_blocks.3.resnets.0.conv2.weight', 'down_blocks.3.resnets.0.conv2.bias', 'down_blocks.3.resnets.1.norm1.weight', 'down_blocks.3.resnets.1.norm1.bias', 'down_blocks.3.resnets.1.conv1.weight', 'down_blocks.3.resnets.1.conv1.bias', 'down_blocks.3.resnets.1.time_emb_proj.weight', 'down_blocks.3.resnets.1.time_emb_proj.bias', 'down_blocks.3.resnets.1.norm2.weight', 'down_blocks.3.resnets.1.norm2.bias', 'down_blocks.3.resnets.1.conv2.weight', 'down_blocks.3.resnets.1.conv2.bias', 'up_blocks.0.resnets.0.norm1.weight', 'up_blocks.0.resnets.0.norm1.bias', 'up_blocks.0.resnets.0.conv1.weight', 'up_blocks.0.resnets.0.conv1.bias', 'up_blocks.0.resnets.0.time_emb_proj.weight', 'up_blocks.0.resnets.0.time_emb_proj.bias', 'up_blocks.0.resnets.0.norm2.weight', 'up_blocks.0.resnets.0.norm2.bias', 'up_blocks.0.resnets.0.conv2.weight', 'up_blocks.0.resnets.0.conv2.bias', 'up_blocks.0.resnets.0.conv_shortcut.weight', 'up_blocks.0.resnets.0.conv_shortcut.bias', 'up_blocks.0.resnets.1.norm1.weight', 'up_blocks.0.resnets.1.norm1.bias', 'up_blocks.0.resnets.1.conv1.weight', 'up_blocks.0.resnets.1.conv1.bias', 'up_blocks.0.resnets.1.time_emb_proj.weight', 'up_blocks.0.resnets.1.time_emb_proj.bias', 'up_blocks.0.resnets.1.norm2.weight', 'up_blocks.0.resnets.1.norm2.bias', 'up_blocks.0.resnets.1.conv2.weight', 'up_blocks.0.resnets.1.conv2.bias', 'up_blocks.0.resnets.1.conv_shortcut.weight', 'up_blocks.0.resnets.1.conv_shortcut.bias', 'up_blocks.0.resnets.2.norm1.weight', 'up_blocks.0.resnets.2.norm1.bias', 'up_blocks.0.resnets.2.conv1.weight', 'up_blocks.0.resnets.2.conv1.bias', 'up_blocks.0.resnets.2.time_emb_proj.weight', 'up_blocks.0.resnets.2.time_emb_proj.bias', 'up_blocks.0.resnets.2.norm2.weight', 'up_blocks.0.resnets.2.norm2.bias', 'up_blocks.0.resnets.2.conv2.weight', 'up_blocks.0.resnets.2.conv2.bias', 'up_blocks.0.resnets.2.conv_shortcut.weight', 'up_blocks.0.resnets.2.conv_shortcut.bias', 'up_blocks.0.upsamplers.0.conv.weight', 'up_blocks.0.upsamplers.0.conv.bias', 'up_blocks.1.attentions.0.norm.weight', 'up_blocks.1.attentions.0.norm.bias', 'up_blocks.1.attentions.0.proj_in.weight', 'up_blocks.1.attentions.0.proj_in.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.norm1.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.norm1.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.norm2.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.norm2.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.norm3.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.norm3.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias', 'up_blocks.1.attentions.0.proj_out.weight', 'up_blocks.1.attentions.0.proj_out.bias', 'up_blocks.1.attentions.1.norm.weight', 'up_blocks.1.attentions.1.norm.bias', 'up_blocks.1.attentions.1.proj_in.weight', 'up_blocks.1.attentions.1.proj_in.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.norm1.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.norm1.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.norm2.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.norm2.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.norm3.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.norm3.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias', 'up_blocks.1.attentions.1.proj_out.weight', 'up_blocks.1.attentions.1.proj_out.bias', 'up_blocks.1.attentions.2.norm.weight', 'up_blocks.1.attentions.2.norm.bias', 'up_blocks.1.attentions.2.proj_in.weight', 'up_blocks.1.attentions.2.proj_in.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.norm1.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.norm1.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.norm2.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.norm2.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.norm3.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.norm3.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.bias', 'up_blocks.1.attentions.2.proj_out.weight', 'up_blocks.1.attentions.2.proj_out.bias', 'up_blocks.1.resnets.0.norm1.weight', 'up_blocks.1.resnets.0.norm1.bias', 'up_blocks.1.resnets.0.conv1.weight', 'up_blocks.1.resnets.0.conv1.bias', 'up_blocks.1.resnets.0.time_emb_proj.weight', 'up_blocks.1.resnets.0.time_emb_proj.bias', 'up_blocks.1.resnets.0.norm2.weight', 'up_blocks.1.resnets.0.norm2.bias', 'up_blocks.1.resnets.0.conv2.weight', 'up_blocks.1.resnets.0.conv2.bias', 'up_blocks.1.resnets.0.conv_shortcut.weight', 'up_blocks.1.resnets.0.conv_shortcut.bias', 'up_blocks.1.resnets.1.norm1.weight', 'up_blocks.1.resnets.1.norm1.bias', 'up_blocks.1.resnets.1.conv1.weight', 'up_blocks.1.resnets.1.conv1.bias', 'up_blocks.1.resnets.1.time_emb_proj.weight', 'up_blocks.1.resnets.1.time_emb_proj.bias', 'up_blocks.1.resnets.1.norm2.weight', 'up_blocks.1.resnets.1.norm2.bias', 'up_blocks.1.resnets.1.conv2.weight', 'up_blocks.1.resnets.1.conv2.bias', 'up_blocks.1.resnets.1.conv_shortcut.weight', 'up_blocks.1.resnets.1.conv_shortcut.bias', 'up_blocks.1.resnets.2.norm1.weight', 'up_blocks.1.resnets.2.norm1.bias', 'up_blocks.1.resnets.2.conv1.weight', 'up_blocks.1.resnets.2.conv1.bias', 'up_blocks.1.resnets.2.time_emb_proj.weight', 'up_blocks.1.resnets.2.time_emb_proj.bias', 'up_blocks.1.resnets.2.norm2.weight', 'up_blocks.1.resnets.2.norm2.bias', 'up_blocks.1.resnets.2.conv2.weight', 'up_blocks.1.resnets.2.conv2.bias', 'up_blocks.1.resnets.2.conv_shortcut.weight', 'up_blocks.1.resnets.2.conv_shortcut.bias', 'up_blocks.1.upsamplers.0.conv.weight', 'up_blocks.1.upsamplers.0.conv.bias', 'up_blocks.2.attentions.0.norm.weight', 'up_blocks.2.attentions.0.norm.bias', 'up_blocks.2.attentions.0.proj_in.weight', 'up_blocks.2.attentions.0.proj_in.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.norm1.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.norm1.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.norm2.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.norm2.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.norm3.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.norm3.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias', 'up_blocks.2.attentions.0.proj_out.weight', 'up_blocks.2.attentions.0.proj_out.bias', 'up_blocks.2.attentions.1.norm.weight', 'up_blocks.2.attentions.1.norm.bias', 'up_blocks.2.attentions.1.proj_in.weight', 'up_blocks.2.attentions.1.proj_in.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.norm1.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.norm1.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.norm2.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.norm2.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.norm3.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.norm3.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias', 'up_blocks.2.attentions.1.proj_out.weight', 'up_blocks.2.attentions.1.proj_out.bias', 'up_blocks.2.attentions.2.norm.weight', 'up_blocks.2.attentions.2.norm.bias', 'up_blocks.2.attentions.2.proj_in.weight', 'up_blocks.2.attentions.2.proj_in.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.norm1.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.norm1.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.norm2.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.norm2.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.norm3.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.norm3.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.ff.net.2.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.ff.net.2.bias', 'up_blocks.2.attentions.2.proj_out.weight', 'up_blocks.2.attentions.2.proj_out.bias', 'up_blocks.2.resnets.0.norm1.weight', 'up_blocks.2.resnets.0.norm1.bias', 'up_blocks.2.resnets.0.conv1.weight', 'up_blocks.2.resnets.0.conv1.bias', 'up_blocks.2.resnets.0.time_emb_proj.weight', 'up_blocks.2.resnets.0.time_emb_proj.bias', 'up_blocks.2.resnets.0.norm2.weight', 'up_blocks.2.resnets.0.norm2.bias', 'up_blocks.2.resnets.0.conv2.weight', 'up_blocks.2.resnets.0.conv2.bias', 'up_blocks.2.resnets.0.conv_shortcut.weight', 'up_blocks.2.resnets.0.conv_shortcut.bias', 'up_blocks.2.resnets.1.norm1.weight', 'up_blocks.2.resnets.1.norm1.bias', 'up_blocks.2.resnets.1.conv1.weight', 'up_blocks.2.resnets.1.conv1.bias', 'up_blocks.2.resnets.1.time_emb_proj.weight', 'up_blocks.2.resnets.1.time_emb_proj.bias', 'up_blocks.2.resnets.1.norm2.weight', 'up_blocks.2.resnets.1.norm2.bias', 'up_blocks.2.resnets.1.conv2.weight', 'up_blocks.2.resnets.1.conv2.bias', 'up_blocks.2.resnets.1.conv_shortcut.weight', 'up_blocks.2.resnets.1.conv_shortcut.bias', 'up_blocks.2.resnets.2.norm1.weight', 'up_blocks.2.resnets.2.norm1.bias', 'up_blocks.2.resnets.2.conv1.weight', 'up_blocks.2.resnets.2.conv1.bias', 'up_blocks.2.resnets.2.time_emb_proj.weight', 'up_blocks.2.resnets.2.time_emb_proj.bias', 'up_blocks.2.resnets.2.norm2.weight', 'up_blocks.2.resnets.2.norm2.bias', 'up_blocks.2.resnets.2.conv2.weight', 'up_blocks.2.resnets.2.conv2.bias', 'up_blocks.2.resnets.2.conv_shortcut.weight', 'up_blocks.2.resnets.2.conv_shortcut.bias', 'up_blocks.2.upsamplers.0.conv.weight', 'up_blocks.2.upsamplers.0.conv.bias', 'up_blocks.3.attentions.0.norm.weight', 'up_blocks.3.attentions.0.norm.bias', 'up_blocks.3.attentions.0.proj_in.weight', 'up_blocks.3.attentions.0.proj_in.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.norm1.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.norm1.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.norm2.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.norm2.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.norm3.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.norm3.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.ff.net.2.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.ff.net.2.bias', 'up_blocks.3.attentions.0.proj_out.weight', 'up_blocks.3.attentions.0.proj_out.bias', 'up_blocks.3.attentions.1.norm.weight', 'up_blocks.3.attentions.1.norm.bias', 'up_blocks.3.attentions.1.proj_in.weight', 'up_blocks.3.attentions.1.proj_in.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.norm1.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.norm1.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.norm2.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.norm2.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.norm3.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.norm3.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.ff.net.2.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.ff.net.2.bias', 'up_blocks.3.attentions.1.proj_out.weight', 'up_blocks.3.attentions.1.proj_out.bias', 'up_blocks.3.attentions.2.norm.weight', 'up_blocks.3.attentions.2.norm.bias', 'up_blocks.3.attentions.2.proj_in.weight', 'up_blocks.3.attentions.2.proj_in.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.norm1.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.norm1.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.norm2.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.norm2.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.norm3.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.norm3.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.ff.net.2.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.ff.net.2.bias', 'up_blocks.3.attentions.2.proj_out.weight', 'up_blocks.3.attentions.2.proj_out.bias', 'up_blocks.3.resnets.0.norm1.weight', 'up_blocks.3.resnets.0.norm1.bias', 'up_blocks.3.resnets.0.conv1.weight', 'up_blocks.3.resnets.0.conv1.bias', 'up_blocks.3.resnets.0.time_emb_proj.weight', 'up_blocks.3.resnets.0.time_emb_proj.bias', 'up_blocks.3.resnets.0.norm2.weight', 'up_blocks.3.resnets.0.norm2.bias', 'up_blocks.3.resnets.0.conv2.weight', 'up_blocks.3.resnets.0.conv2.bias', 'up_blocks.3.resnets.0.conv_shortcut.weight', 'up_blocks.3.resnets.0.conv_shortcut.bias', 'up_blocks.3.resnets.1.norm1.weight', 'up_blocks.3.resnets.1.norm1.bias', 'up_blocks.3.resnets.1.conv1.weight', 'up_blocks.3.resnets.1.conv1.bias', 'up_blocks.3.resnets.1.time_emb_proj.weight', 'up_blocks.3.resnets.1.time_emb_proj.bias', 'up_blocks.3.resnets.1.norm2.weight', 'up_blocks.3.resnets.1.norm2.bias', 'up_blocks.3.resnets.1.conv2.weight', 'up_blocks.3.resnets.1.conv2.bias', 'up_blocks.3.resnets.1.conv_shortcut.weight', 'up_blocks.3.resnets.1.conv_shortcut.bias', 'up_blocks.3.resnets.2.norm1.weight', 'up_blocks.3.resnets.2.norm1.bias', 'up_blocks.3.resnets.2.conv1.weight', 'up_blocks.3.resnets.2.conv1.bias', 'up_blocks.3.resnets.2.time_emb_proj.weight', 'up_blocks.3.resnets.2.time_emb_proj.bias', 'up_blocks.3.resnets.2.norm2.weight', 'up_blocks.3.resnets.2.norm2.bias', 'up_blocks.3.resnets.2.conv2.weight', 'up_blocks.3.resnets.2.conv2.bias', 'up_blocks.3.resnets.2.conv_shortcut.weight', 'up_blocks.3.resnets.2.conv_shortcut.bias', 'mid_block.attentions.0.norm.weight', 'mid_block.attentions.0.norm.bias', 'mid_block.attentions.0.proj_in.weight', 'mid_block.attentions.0.proj_in.bias', 'mid_block.attentions.0.transformer_blocks.0.norm1.weight', 'mid_block.attentions.0.transformer_blocks.0.norm1.bias', 'mid_block.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'mid_block.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'mid_block.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'mid_block.attentions.0.transformer_blocks.0.norm2.weight', 'mid_block.attentions.0.transformer_blocks.0.norm2.bias', 'mid_block.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'mid_block.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'mid_block.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'mid_block.attentions.0.transformer_blocks.0.norm3.weight', 'mid_block.attentions.0.transformer_blocks.0.norm3.bias', 'mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'mid_block.attentions.0.transformer_blocks.0.ff.net.2.weight', 'mid_block.attentions.0.transformer_blocks.0.ff.net.2.bias', 'mid_block.attentions.0.proj_out.weight', 'mid_block.attentions.0.proj_out.bias', 'mid_block.resnets.0.norm1.weight', 'mid_block.resnets.0.norm1.bias', 'mid_block.resnets.0.conv1.weight', 'mid_block.resnets.0.conv1.bias', 'mid_block.resnets.0.time_emb_proj.weight', 'mid_block.resnets.0.time_emb_proj.bias', 'mid_block.resnets.0.norm2.weight', 'mid_block.resnets.0.norm2.bias', 'mid_block.resnets.0.conv2.weight', 'mid_block.resnets.0.conv2.bias', 'mid_block.resnets.1.norm1.weight', 'mid_block.resnets.1.norm1.bias', 'mid_block.resnets.1.conv1.weight', 'mid_block.resnets.1.conv1.bias', 'mid_block.resnets.1.time_emb_proj.weight', 'mid_block.resnets.1.time_emb_proj.bias', 'mid_block.resnets.1.norm2.weight', 'mid_block.resnets.1.norm2.bias', 'mid_block.resnets.1.conv2.weight', 'mid_block.resnets.1.conv2.bias', 'conv_norm_out.weight', 'conv_norm_out.bias', 'conv_out.weight', 'conv_out.bias'], Unexpected: ['input_blocks.0.0.bias', 'input_blocks.0.0.weight', 'input_blocks.1.0.emb_layers.1.bias', 'input_blocks.1.0.emb_layers.1.weight', 'input_blocks.1.0.in_layers.0.bias', 'input_blocks.1.0.in_layers.0.weight', 'input_blocks.1.0.in_layers.2.bias', 'input_blocks.1.0.in_layers.2.weight', 'input_blocks.1.0.out_layers.0.bias', 'input_blocks.1.0.out_layers.0.weight', 'input_blocks.1.0.out_layers.3.bias', 'input_blocks.1.0.out_layers.3.weight', 'input_blocks.1.1.norm.bias', 'input_blocks.1.1.norm.weight', 'input_blocks.1.1.proj_in.bias', 'input_blocks.1.1.proj_in.weight', 'input_blocks.1.1.proj_out.bias', 'input_blocks.1.1.proj_out.weight', 'input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight', 'input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias', 'input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight', 'input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight', 'input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight', 'input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight', 'input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias', 'input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight', 'input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight', 'input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight', 'input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias', 'input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight', 'input_blocks.1.1.transformer_blocks.0.ff.net.2.bias', 'input_blocks.1.1.transformer_blocks.0.ff.net.2.weight', 'input_blocks.1.1.transformer_blocks.0.norm1.bias', 'input_blocks.1.1.transformer_blocks.0.norm1.weight', 'input_blocks.1.1.transformer_blocks.0.norm2.bias', 'input_blocks.1.1.transformer_blocks.0.norm2.weight', 'input_blocks.1.1.transformer_blocks.0.norm3.bias', 'input_blocks.1.1.transformer_blocks.0.norm3.weight', 'input_blocks.10.0.emb_layers.1.bias', 'input_blocks.10.0.emb_layers.1.weight', 'input_blocks.10.0.in_layers.0.bias', 'input_blocks.10.0.in_layers.0.weight', 'input_blocks.10.0.in_layers.2.bias', 'input_blocks.10.0.in_layers.2.weight', 'input_blocks.10.0.out_layers.0.bias', 'input_blocks.10.0.out_layers.0.weight', 'input_blocks.10.0.out_layers.3.bias', 'input_blocks.10.0.out_layers.3.weight', 'input_blocks.11.0.emb_layers.1.bias', 'input_blocks.11.0.emb_layers.1.weight', 'input_blocks.11.0.in_layers.0.bias', 'input_blocks.11.0.in_layers.0.weight', 'input_blocks.11.0.in_layers.2.bias', 'input_blocks.11.0.in_layers.2.weight', 'input_blocks.11.0.out_layers.0.bias', 'input_blocks.11.0.out_layers.0.weight', 'input_blocks.11.0.out_layers.3.bias', 'input_blocks.11.0.out_layers.3.weight', 'input_blocks.2.0.emb_layers.1.bias', 'input_blocks.2.0.emb_layers.1.weight', 'input_blocks.2.0.in_layers.0.bias', 'input_blocks.2.0.in_layers.0.weight', 'input_blocks.2.0.in_layers.2.bias', 'input_blocks.2.0.in_layers.2.weight', 'input_blocks.2.0.out_layers.0.bias', 'input_blocks.2.0.out_layers.0.weight', 'input_blocks.2.0.out_layers.3.bias', 'input_blocks.2.0.out_layers.3.weight', 'input_blocks.2.1.norm.bias', 'input_blocks.2.1.norm.weight', 'input_blocks.2.1.proj_in.bias', 'input_blocks.2.1.proj_in.weight', 'input_blocks.2.1.proj_out.bias', 'input_blocks.2.1.proj_out.weight', 'input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight', 'input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias', 'input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight', 'input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight', 'input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight', 'input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight', 'input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias', 'input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight', 'input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight', 'input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight', 'input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias', 'input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight', 'input_blocks.2.1.transformer_blocks.0.ff.net.2.bias', 'input_blocks.2.1.transformer_blocks.0.ff.net.2.weight', 'input_blocks.2.1.transformer_blocks.0.norm1.bias', 'input_blocks.2.1.transformer_blocks.0.norm1.weight', 'input_blocks.2.1.transformer_blocks.0.norm2.bias', 'input_blocks.2.1.transformer_blocks.0.norm2.weight', 'input_blocks.2.1.transformer_blocks.0.norm3.bias', 'input_blocks.2.1.transformer_blocks.0.norm3.weight', 'input_blocks.3.0.op.bias', 'input_blocks.3.0.op.weight', 'input_blocks.4.0.emb_layers.1.bias', 'input_blocks.4.0.emb_layers.1.weight', 'input_blocks.4.0.in_layers.0.bias', 'input_blocks.4.0.in_layers.0.weight', 'input_blocks.4.0.in_layers.2.bias', 'input_blocks.4.0.in_layers.2.weight', 'input_blocks.4.0.out_layers.0.bias', 'input_blocks.4.0.out_layers.0.weight', 'input_blocks.4.0.out_layers.3.bias', 'input_blocks.4.0.out_layers.3.weight', 'input_blocks.4.0.skip_connection.bias', 'input_blocks.4.0.skip_connection.weight', 'input_blocks.4.1.norm.bias', 'input_blocks.4.1.norm.weight', 'input_blocks.4.1.proj_in.bias', 'input_blocks.4.1.proj_in.weight', 'input_blocks.4.1.proj_out.bias', 'input_blocks.4.1.proj_out.weight', 'input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'input_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'input_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'input_blocks.4.1.transformer_blocks.0.norm1.bias', 'input_blocks.4.1.transformer_blocks.0.norm1.weight', 'input_blocks.4.1.transformer_blocks.0.norm2.bias', 'input_blocks.4.1.transformer_blocks.0.norm2.weight', 'input_blocks.4.1.transformer_blocks.0.norm3.bias', 'input_blocks.4.1.transformer_blocks.0.norm3.weight', 'input_blocks.5.0.emb_layers.1.bias', 'input_blocks.5.0.emb_layers.1.weight', 'input_blocks.5.0.in_layers.0.bias', 'input_blocks.5.0.in_layers.0.weight', 'input_blocks.5.0.in_layers.2.bias', 'input_blocks.5.0.in_layers.2.weight', 'input_blocks.5.0.out_layers.0.bias', 'input_blocks.5.0.out_layers.0.weight', 'input_blocks.5.0.out_layers.3.bias', 'input_blocks.5.0.out_layers.3.weight', 'input_blocks.5.1.norm.bias', 'input_blocks.5.1.norm.weight', 'input_blocks.5.1.proj_in.bias', 'input_blocks.5.1.proj_in.weight', 'input_blocks.5.1.proj_out.bias', 'input_blocks.5.1.proj_out.weight', 'input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'input_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'input_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'input_blocks.5.1.transformer_blocks.0.norm1.bias', 'input_blocks.5.1.transformer_blocks.0.norm1.weight', 'input_blocks.5.1.transformer_blocks.0.norm2.bias', 'input_blocks.5.1.transformer_blocks.0.norm2.weight', 'input_blocks.5.1.transformer_blocks.0.norm3.bias', 'input_blocks.5.1.transformer_blocks.0.norm3.weight', 'input_blocks.6.0.op.bias', 'input_blocks.6.0.op.weight', 'input_blocks.7.0.emb_layers.1.bias', 'input_blocks.7.0.emb_layers.1.weight', 'input_blocks.7.0.in_layers.0.bias', 'input_blocks.7.0.in_layers.0.weight', 'input_blocks.7.0.in_layers.2.bias', 'input_blocks.7.0.in_layers.2.weight', 'input_blocks.7.0.out_layers.0.bias', 'input_blocks.7.0.out_layers.0.weight', 'input_blocks.7.0.out_layers.3.bias', 'input_blocks.7.0.out_layers.3.weight', 'input_blocks.7.0.skip_connection.bias', 'input_blocks.7.0.skip_connection.weight', 'input_blocks.7.1.norm.bias', 'input_blocks.7.1.norm.weight', 'input_blocks.7.1.proj_in.bias', 'input_blocks.7.1.proj_in.weight', 'input_blocks.7.1.proj_out.bias', 'input_blocks.7.1.proj_out.weight', 'input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'input_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'input_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'input_blocks.7.1.transformer_blocks.0.norm1.bias', 'input_blocks.7.1.transformer_blocks.0.norm1.weight', 'input_blocks.7.1.transformer_blocks.0.norm2.bias', 'input_blocks.7.1.transformer_blocks.0.norm2.weight', 'input_blocks.7.1.transformer_blocks.0.norm3.bias', 'input_blocks.7.1.transformer_blocks.0.norm3.weight', 'input_blocks.8.0.emb_layers.1.bias', 'input_blocks.8.0.emb_layers.1.weight', 'input_blocks.8.0.in_layers.0.bias', 'input_blocks.8.0.in_layers.0.weight', 'input_blocks.8.0.in_layers.2.bias', 'input_blocks.8.0.in_layers.2.weight', 'input_blocks.8.0.out_layers.0.bias', 'input_blocks.8.0.out_layers.0.weight', 'input_blocks.8.0.out_layers.3.bias', 'input_blocks.8.0.out_layers.3.weight', 'input_blocks.8.1.norm.bias', 'input_blocks.8.1.norm.weight', 'input_blocks.8.1.proj_in.bias', 'input_blocks.8.1.proj_in.weight', 'input_blocks.8.1.proj_out.bias', 'input_blocks.8.1.proj_out.weight', 'input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'input_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'input_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'input_blocks.8.1.transformer_blocks.0.norm1.bias', 'input_blocks.8.1.transformer_blocks.0.norm1.weight', 'input_blocks.8.1.transformer_blocks.0.norm2.bias', 'input_blocks.8.1.transformer_blocks.0.norm2.weight', 'input_blocks.8.1.transformer_blocks.0.norm3.bias', 'input_blocks.8.1.transformer_blocks.0.norm3.weight', 'input_blocks.9.0.op.bias', 'input_blocks.9.0.op.weight', 'middle_block.0.emb_layers.1.bias', 'middle_block.0.emb_layers.1.weight', 'middle_block.0.in_layers.0.bias', 'middle_block.0.in_layers.0.weight', 'middle_block.0.in_layers.2.bias', 'middle_block.0.in_layers.2.weight', 'middle_block.0.out_layers.0.bias', 'middle_block.0.out_layers.0.weight', 'middle_block.0.out_layers.3.bias', 'middle_block.0.out_layers.3.weight', 'middle_block.1.norm.bias', 'middle_block.1.norm.weight', 'middle_block.1.proj_in.bias', 'middle_block.1.proj_in.weight', 'middle_block.1.proj_out.bias', 'middle_block.1.proj_out.weight', 'middle_block.1.transformer_blocks.0.attn1.to_k.weight', 'middle_block.1.transformer_blocks.0.attn1.to_out.0.bias', 'middle_block.1.transformer_blocks.0.attn1.to_out.0.weight', 'middle_block.1.transformer_blocks.0.attn1.to_q.weight', 'middle_block.1.transformer_blocks.0.attn1.to_v.weight', 'middle_block.1.transformer_blocks.0.attn2.to_k.weight', 'middle_block.1.transformer_blocks.0.attn2.to_out.0.bias', 'middle_block.1.transformer_blocks.0.attn2.to_out.0.weight', 'middle_block.1.transformer_blocks.0.attn2.to_q.weight', 'middle_block.1.transformer_blocks.0.attn2.to_v.weight', 'middle_block.1.transformer_blocks.0.ff.net.0.proj.bias', 'middle_block.1.transformer_blocks.0.ff.net.0.proj.weight', 'middle_block.1.transformer_blocks.0.ff.net.2.bias', 'middle_block.1.transformer_blocks.0.ff.net.2.weight', 'middle_block.1.transformer_blocks.0.norm1.bias', 'middle_block.1.transformer_blocks.0.norm1.weight', 'middle_block.1.transformer_blocks.0.norm2.bias', 'middle_block.1.transformer_blocks.0.norm2.weight', 'middle_block.1.transformer_blocks.0.norm3.bias', 'middle_block.1.transformer_blocks.0.norm3.weight', 'middle_block.2.emb_layers.1.bias', 'middle_block.2.emb_layers.1.weight', 'middle_block.2.in_layers.0.bias', 'middle_block.2.in_layers.0.weight', 'middle_block.2.in_layers.2.bias', 'middle_block.2.in_layers.2.weight', 'middle_block.2.out_layers.0.bias', 'middle_block.2.out_layers.0.weight', 'middle_block.2.out_layers.3.bias', 'middle_block.2.out_layers.3.weight', 'out.0.bias', 'out.0.weight', 'out.2.bias', 'out.2.weight', 'output_blocks.0.0.emb_layers.1.bias', 'output_blocks.0.0.emb_layers.1.weight', 'output_blocks.0.0.in_layers.0.bias', 'output_blocks.0.0.in_layers.0.weight', 'output_blocks.0.0.in_layers.2.bias', 'output_blocks.0.0.in_layers.2.weight', 'output_blocks.0.0.out_layers.0.bias', 'output_blocks.0.0.out_layers.0.weight', 'output_blocks.0.0.out_layers.3.bias', 'output_blocks.0.0.out_layers.3.weight', 'output_blocks.0.0.skip_connection.bias', 'output_blocks.0.0.skip_connection.weight', 'output_blocks.1.0.emb_layers.1.bias', 'output_blocks.1.0.emb_layers.1.weight', 'output_blocks.1.0.in_layers.0.bias', 'output_blocks.1.0.in_layers.0.weight', 'output_blocks.1.0.in_layers.2.bias', 'output_blocks.1.0.in_layers.2.weight', 'output_blocks.1.0.out_layers.0.bias', 'output_blocks.1.0.out_layers.0.weight', 'output_blocks.1.0.out_layers.3.bias', 'output_blocks.1.0.out_layers.3.weight', 'output_blocks.1.0.skip_connection.bias', 'output_blocks.1.0.skip_connection.weight', 'output_blocks.10.0.emb_layers.1.bias', 'output_blocks.10.0.emb_layers.1.weight', 'output_blocks.10.0.in_layers.0.bias', 'output_blocks.10.0.in_layers.0.weight', 'output_blocks.10.0.in_layers.2.bias', 'output_blocks.10.0.in_layers.2.weight', 'output_blocks.10.0.out_layers.0.bias', 'output_blocks.10.0.out_layers.0.weight', 'output_blocks.10.0.out_layers.3.bias', 'output_blocks.10.0.out_layers.3.weight', 'output_blocks.10.0.skip_connection.bias', 'output_blocks.10.0.skip_connection.weight', 'output_blocks.10.1.norm.bias', 'output_blocks.10.1.norm.weight', 'output_blocks.10.1.proj_in.bias', 'output_blocks.10.1.proj_in.weight', 'output_blocks.10.1.proj_out.bias', 'output_blocks.10.1.proj_out.weight', 'output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight', 'output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias', 'output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight', 'output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight', 'output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight', 'output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight', 'output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias', 'output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight', 'output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight', 'output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight', 'output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias', 'output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight', 'output_blocks.10.1.transformer_blocks.0.ff.net.2.bias', 'output_blocks.10.1.transformer_blocks.0.ff.net.2.weight', 'output_blocks.10.1.transformer_blocks.0.norm1.bias', 'output_blocks.10.1.transformer_blocks.0.norm1.weight', 'output_blocks.10.1.transformer_blocks.0.norm2.bias', 'output_blocks.10.1.transformer_blocks.0.norm2.weight', 'output_blocks.10.1.transformer_blocks.0.norm3.bias', 'output_blocks.10.1.transformer_blocks.0.norm3.weight', 'output_blocks.11.0.emb_layers.1.bias', 'output_blocks.11.0.emb_layers.1.weight', 'output_blocks.11.0.in_layers.0.bias', 'output_blocks.11.0.in_layers.0.weight', 'output_blocks.11.0.in_layers.2.bias', 'output_blocks.11.0.in_layers.2.weight', 'output_blocks.11.0.out_layers.0.bias', 'output_blocks.11.0.out_layers.0.weight', 'output_blocks.11.0.out_layers.3.bias', 'output_blocks.11.0.out_layers.3.weight', 'output_blocks.11.0.skip_connection.bias', 'output_blocks.11.0.skip_connection.weight', 'output_blocks.11.1.norm.bias', 'output_blocks.11.1.norm.weight', 'output_blocks.11.1.proj_in.bias', 'output_blocks.11.1.proj_in.weight', 'output_blocks.11.1.proj_out.bias', 'output_blocks.11.1.proj_out.weight', 'output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight', 'output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias', 'output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight', 'output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight', 'output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight', 'output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight', 'output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias', 'output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight', 'output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight', 'output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight', 'output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias', 'output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight', 'output_blocks.11.1.transformer_blocks.0.ff.net.2.bias', 'output_blocks.11.1.transformer_blocks.0.ff.net.2.weight', 'output_blocks.11.1.transformer_blocks.0.norm1.bias', 'output_blocks.11.1.transformer_blocks.0.norm1.weight', 'output_blocks.11.1.transformer_blocks.0.norm2.bias', 'output_blocks.11.1.transformer_blocks.0.norm2.weight', 'output_blocks.11.1.transformer_blocks.0.norm3.bias', 'output_blocks.11.1.transformer_blocks.0.norm3.weight', 'output_blocks.2.0.emb_layers.1.bias', 'output_blocks.2.0.emb_layers.1.weight', 'output_blocks.2.0.in_layers.0.bias', 'output_blocks.2.0.in_layers.0.weight', 'output_blocks.2.0.in_layers.2.bias', 'output_blocks.2.0.in_layers.2.weight', 'output_blocks.2.0.out_layers.0.bias', 'output_blocks.2.0.out_layers.0.weight', 'output_blocks.2.0.out_layers.3.bias', 'output_blocks.2.0.out_layers.3.weight', 'output_blocks.2.0.skip_connection.bias', 'output_blocks.2.0.skip_connection.weight', 'output_blocks.2.1.conv.bias', 'output_blocks.2.1.conv.weight', 'output_blocks.3.0.emb_layers.1.bias', 'output_blocks.3.0.emb_layers.1.weight', 'output_blocks.3.0.in_layers.0.bias', 'output_blocks.3.0.in_layers.0.weight', 'output_blocks.3.0.in_layers.2.bias', 'output_blocks.3.0.in_layers.2.weight', 'output_blocks.3.0.out_layers.0.bias', 'output_blocks.3.0.out_layers.0.weight', 'output_blocks.3.0.out_layers.3.bias', 'output_blocks.3.0.out_layers.3.weight', 'output_blocks.3.0.skip_connection.bias', 'output_blocks.3.0.skip_connection.weight', 'output_blocks.3.1.norm.bias', 'output_blocks.3.1.norm.weight', 'output_blocks.3.1.proj_in.bias', 'output_blocks.3.1.proj_in.weight', 'output_blocks.3.1.proj_out.bias', 'output_blocks.3.1.proj_out.weight', 'output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight', 'output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias', 'output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight', 'output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight', 'output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight', 'output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight', 'output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias', 'output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight', 'output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight', 'output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight', 'output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias', 'output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight', 'output_blocks.3.1.transformer_blocks.0.ff.net.2.bias', 'output_blocks.3.1.transformer_blocks.0.ff.net.2.weight', 'output_blocks.3.1.transformer_blocks.0.norm1.bias', 'output_blocks.3.1.transformer_blocks.0.norm1.weight', 'output_blocks.3.1.transformer_blocks.0.norm2.bias', 'output_blocks.3.1.transformer_blocks.0.norm2.weight', 'output_blocks.3.1.transformer_blocks.0.norm3.bias', 'output_blocks.3.1.transformer_blocks.0.norm3.weight', 'output_blocks.4.0.emb_layers.1.bias', 'output_blocks.4.0.emb_layers.1.weight', 'output_blocks.4.0.in_layers.0.bias', 'output_blocks.4.0.in_layers.0.weight', 'output_blocks.4.0.in_layers.2.bias', 'output_blocks.4.0.in_layers.2.weight', 'output_blocks.4.0.out_layers.0.bias', 'output_blocks.4.0.out_layers.0.weight', 'output_blocks.4.0.out_layers.3.bias', 'output_blocks.4.0.out_layers.3.weight', 'output_blocks.4.0.skip_connection.bias', 'output_blocks.4.0.skip_connection.weight', 'output_blocks.4.1.norm.bias', 'output_blocks.4.1.norm.weight', 'output_blocks.4.1.proj_in.bias', 'output_blocks.4.1.proj_in.weight', 'output_blocks.4.1.proj_out.bias', 'output_blocks.4.1.proj_out.weight', 'output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'output_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'output_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'output_blocks.4.1.transformer_blocks.0.norm1.bias', 'output_blocks.4.1.transformer_blocks.0.norm1.weight', 'output_blocks.4.1.transformer_blocks.0.norm2.bias', 'output_blocks.4.1.transformer_blocks.0.norm2.weight', 'output_blocks.4.1.transformer_blocks.0.norm3.bias', 'output_blocks.4.1.transformer_blocks.0.norm3.weight', 'output_blocks.5.0.emb_layers.1.bias', 'output_blocks.5.0.emb_layers.1.weight', 'output_blocks.5.0.in_layers.0.bias', 'output_blocks.5.0.in_layers.0.weight', 'output_blocks.5.0.in_layers.2.bias', 'output_blocks.5.0.in_layers.2.weight', 'output_blocks.5.0.out_layers.0.bias', 'output_blocks.5.0.out_layers.0.weight', 'output_blocks.5.0.out_layers.3.bias', 'output_blocks.5.0.out_layers.3.weight', 'output_blocks.5.0.skip_connection.bias', 'output_blocks.5.0.skip_connection.weight', 'output_blocks.5.1.norm.bias', 'output_blocks.5.1.norm.weight', 'output_blocks.5.1.proj_in.bias', 'output_blocks.5.1.proj_in.weight', 'output_blocks.5.1.proj_out.bias', 'output_blocks.5.1.proj_out.weight', 'output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'output_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'output_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'output_blocks.5.1.transformer_blocks.0.norm1.bias', 'output_blocks.5.1.transformer_blocks.0.norm1.weight', 'output_blocks.5.1.transformer_blocks.0.norm2.bias', 'output_blocks.5.1.transformer_blocks.0.norm2.weight', 'output_blocks.5.1.transformer_blocks.0.norm3.bias', 'output_blocks.5.1.transformer_blocks.0.norm3.weight', 'output_blocks.5.2.conv.bias', 'output_blocks.5.2.conv.weight', 'output_blocks.6.0.emb_layers.1.bias', 'output_blocks.6.0.emb_layers.1.weight', 'output_blocks.6.0.in_layers.0.bias', 'output_blocks.6.0.in_layers.0.weight', 'output_blocks.6.0.in_layers.2.bias', 'output_blocks.6.0.in_layers.2.weight', 'output_blocks.6.0.out_layers.0.bias', 'output_blocks.6.0.out_layers.0.weight', 'output_blocks.6.0.out_layers.3.bias', 'output_blocks.6.0.out_layers.3.weight', 'output_blocks.6.0.skip_connection.bias', 'output_blocks.6.0.skip_connection.weight', 'output_blocks.6.1.norm.bias', 'output_blocks.6.1.norm.weight', 'output_blocks.6.1.proj_in.bias', 'output_blocks.6.1.proj_in.weight', 'output_blocks.6.1.proj_out.bias', 'output_blocks.6.1.proj_out.weight', 'output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight', 'output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias', 'output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight', 'output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight', 'output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight', 'output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight', 'output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias', 'output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight', 'output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight', 'output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight', 'output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias', 'output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight', 'output_blocks.6.1.transformer_blocks.0.ff.net.2.bias', 'output_blocks.6.1.transformer_blocks.0.ff.net.2.weight', 'output_blocks.6.1.transformer_blocks.0.norm1.bias', 'output_blocks.6.1.transformer_blocks.0.norm1.weight', 'output_blocks.6.1.transformer_blocks.0.norm2.bias', 'output_blocks.6.1.transformer_blocks.0.norm2.weight', 'output_blocks.6.1.transformer_blocks.0.norm3.bias', 'output_blocks.6.1.transformer_blocks.0.norm3.weight', 'output_blocks.7.0.emb_layers.1.bias', 'output_blocks.7.0.emb_layers.1.weight', 'output_blocks.7.0.in_layers.0.bias', 'output_blocks.7.0.in_layers.0.weight', 'output_blocks.7.0.in_layers.2.bias', 'output_blocks.7.0.in_layers.2.weight', 'output_blocks.7.0.out_layers.0.bias', 'output_blocks.7.0.out_layers.0.weight', 'output_blocks.7.0.out_layers.3.bias', 'output_blocks.7.0.out_layers.3.weight', 'output_blocks.7.0.skip_connection.bias', 'output_blocks.7.0.skip_connection.weight', 'output_blocks.7.1.norm.bias', 'output_blocks.7.1.norm.weight', 'output_blocks.7.1.proj_in.bias', 'output_blocks.7.1.proj_in.weight', 'output_blocks.7.1.proj_out.bias', 'output_blocks.7.1.proj_out.weight', 'output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'output_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'output_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'output_blocks.7.1.transformer_blocks.0.norm1.bias', 'output_blocks.7.1.transformer_blocks.0.norm1.weight', 'output_blocks.7.1.transformer_blocks.0.norm2.bias', 'output_blocks.7.1.transformer_blocks.0.norm2.weight', 'output_blocks.7.1.transformer_blocks.0.norm3.bias', 'output_blocks.7.1.transformer_blocks.0.norm3.weight', 'output_blocks.8.0.emb_layers.1.bias', 'output_blocks.8.0.emb_layers.1.weight', 'output_blocks.8.0.in_layers.0.bias', 'output_blocks.8.0.in_layers.0.weight', 'output_blocks.8.0.in_layers.2.bias', 'output_blocks.8.0.in_layers.2.weight', 'output_blocks.8.0.out_layers.0.bias', 'output_blocks.8.0.out_layers.0.weight', 'output_blocks.8.0.out_layers.3.bias', 'output_blocks.8.0.out_layers.3.weight', 'output_blocks.8.0.skip_connection.bias', 'output_blocks.8.0.skip_connection.weight', 'output_blocks.8.1.norm.bias', 'output_blocks.8.1.norm.weight', 'output_blocks.8.1.proj_in.bias', 'output_blocks.8.1.proj_in.weight', 'output_blocks.8.1.proj_out.bias', 'output_blocks.8.1.proj_out.weight', 'output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'output_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'output_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'output_blocks.8.1.transformer_blocks.0.norm1.bias', 'output_blocks.8.1.transformer_blocks.0.norm1.weight', 'output_blocks.8.1.transformer_blocks.0.norm2.bias', 'output_blocks.8.1.transformer_blocks.0.norm2.weight', 'output_blocks.8.1.transformer_blocks.0.norm3.bias', 'output_blocks.8.1.transformer_blocks.0.norm3.weight', 'output_blocks.8.2.conv.bias', 'output_blocks.8.2.conv.weight', 'output_blocks.9.0.emb_layers.1.bias', 'output_blocks.9.0.emb_layers.1.weight', 'output_blocks.9.0.in_layers.0.bias', 'output_blocks.9.0.in_layers.0.weight', 'output_blocks.9.0.in_layers.2.bias', 'output_blocks.9.0.in_layers.2.weight', 'output_blocks.9.0.out_layers.0.bias', 'output_blocks.9.0.out_layers.0.weight', 'output_blocks.9.0.out_layers.3.bias', 'output_blocks.9.0.out_layers.3.weight', 'output_blocks.9.0.skip_connection.bias', 'output_blocks.9.0.skip_connection.weight', 'output_blocks.9.1.norm.bias', 'output_blocks.9.1.norm.weight', 'output_blocks.9.1.proj_in.bias', 'output_blocks.9.1.proj_in.weight', 'output_blocks.9.1.proj_out.bias', 'output_blocks.9.1.proj_out.weight', 'output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight', 'output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias', 'output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight', 'output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight', 'output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight', 'output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight', 'output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias', 'output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight', 'output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight', 'output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight', 'output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias', 'output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight', 'output_blocks.9.1.transformer_blocks.0.ff.net.2.bias', 'output_blocks.9.1.transformer_blocks.0.ff.net.2.weight', 'output_blocks.9.1.transformer_blocks.0.norm1.bias', 'output_blocks.9.1.transformer_blocks.0.norm1.weight', 'output_blocks.9.1.transformer_blocks.0.norm2.bias', 'output_blocks.9.1.transformer_blocks.0.norm2.weight', 'output_blocks.9.1.transformer_blocks.0.norm3.bias', 'output_blocks.9.1.transformer_blocks.0.norm3.weight', 'time_embed.0.bias', 'time_embed.0.weight', 'time_embed.2.bias', 'time_embed.2.weight']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from research.ip_adapter_module import IPAdapterModule\n",
    "from safetensors.torch import load_file\n",
    "# 1. \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ckpt_path = \"C:/comfy/ComfyUI_windows_portable/ComfyUI/models/checkpoints/dreamshaper_8.safetensors\"   #    SDXL\n",
    "adapter_ckpt = \"C:/comfy/ComfyUI_windows_portable/ComfyUI/models/ipadapter/ip-adapter-plus_sd15.safetensors\"\n",
    "clip_repo = \"laion/CLIP-ViT-H-14-laion2B-s32B-b79K\"\n",
    "\n",
    "# 2.    \n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)\n",
    "unet = pipe.unet\n",
    "state_dict = load_file(ckpt_path)  #   {param_name: tensor}\n",
    "\n",
    "#      UNet\n",
    "unet_keys = [k for k in state_dict.keys() if k.startswith(\"model.diffusion_model.\")]\n",
    "mapped_state_dict = {\n",
    "    k.replace(\"model.diffusion_model.\", \"\"): v for k, v in state_dict.items() if k.startswith(\"model.diffusion_model.\")\n",
    "}\n",
    "missing, unexpected = unet.load_state_dict(mapped_state_dict, strict=False)\n",
    "print(f\"Missing: {missing}, Unexpected: {unexpected}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb2e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a5b21ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CLIPVisionModelWithProjection:\n\tsize mismatch for visual_projection.weight: copying a param with shape torch.Size([1024, 1280]) from checkpoint, the shape in current model is torch.Size([768, 1280]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m adapter \u001b[38;5;241m=\u001b[39m \u001b[43mIPAdapterModule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43madapter_ckpt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madapter_ckpt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_encoder_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_repo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_plus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attention_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m768\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers_to_patch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#      3\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 3.  UNet\u001b[39;00m\n\u001b[0;32m     12\u001b[0m adapter\u001b[38;5;241m.\u001b[39mpatch_unet(pipe\u001b[38;5;241m.\u001b[39munet)\n",
      "File \u001b[1;32mc:\\Jup\\\\IFA\\research\\ip_adapter_module.py:230\u001b[0m, in \u001b[0;36mIPAdapterModule.__init__\u001b[1;34m(self, adapter_ckpt, image_encoder_repo, device, num_tokens, is_plus, cross_attention_dim, layers_to_patch)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_to_patch \u001b[38;5;241m=\u001b[39m layers_to_patch\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# CLIP vision encoder\u001b[39;00m\n\u001b[1;32m--> 230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip \u001b[38;5;241m=\u001b[39m \u001b[43mCLIPVisionModelWithProjection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_encoder_repo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprojection_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attention_dim\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor \u001b[38;5;241m=\u001b[39m CLIPImageProcessor()\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m# Image projection model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\pip-torch\\Lib\\site-packages\\transformers\\modeling_utils.py:4225\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   4215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4216\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[0;32m   4218\u001b[0m     (\n\u001b[0;32m   4219\u001b[0m         model,\n\u001b[0;32m   4220\u001b[0m         missing_keys,\n\u001b[0;32m   4221\u001b[0m         unexpected_keys,\n\u001b[0;32m   4222\u001b[0m         mismatched_keys,\n\u001b[0;32m   4223\u001b[0m         offload_index,\n\u001b[0;32m   4224\u001b[0m         error_msgs,\n\u001b[1;32m-> 4225\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[0;32m   4229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4232\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4233\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4236\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4237\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4243\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4245\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[0;32m   4246\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\pip-torch\\Lib\\site-packages\\transformers\\modeling_utils.py:4785\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[1;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path, weights_only)\u001b[0m\n\u001b[0;32m   4781\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize mismatch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_msg:\n\u001b[0;32m   4782\u001b[0m         error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   4783\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4784\u001b[0m         )\n\u001b[1;32m-> 4785\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unexpected_keys) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   4788\u001b[0m     archs \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39marchitectures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39marchitectures\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CLIPVisionModelWithProjection:\n\tsize mismatch for visual_projection.weight: copying a param with shape torch.Size([1024, 1280]) from checkpoint, the shape in current model is torch.Size([768, 1280]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method."
     ]
    }
   ],
   "source": [
    "adapter = IPAdapterModule(\n",
    "    adapter_ckpt=adapter_ckpt,\n",
    "    image_encoder_repo=clip_repo,\n",
    "    device=device,\n",
    "    num_tokens=16,\n",
    "    is_plus=True,\n",
    "    cross_attention_dim=768,\n",
    "    layers_to_patch=[3]  #      3\n",
    ")\n",
    "\n",
    "# 3.  UNet\n",
    "adapter.patch_unet(pipe.unet)\n",
    "\n",
    "# 4.   \n",
    "prompts = [\"A futuristic cityscape\", \"A serene mountain lake\"]\n",
    "#     image-conditioning\n",
    "img1 = Image.open(\"left.jpg\").convert(\"RGB\")\n",
    "img2 = Image.open(\"right.jpg\").convert(\"RGB\")\n",
    "\n",
    "#       \n",
    "w, h = img1.size\n",
    "mask_left  = torch.from_numpy(np.tile([[1]* (w//2) + [0]* (w - w//2)], (h,1))).float()\n",
    "mask_right = 1 - mask_left\n",
    "\n",
    "#   \n",
    "image_prompts = [img1, img2]\n",
    "masks = [mask_left, mask_right]\n",
    "\n",
    "# 5.  \n",
    "images = adapter.generate_batch(\n",
    "    pipe=pipe,\n",
    "    prompts=prompts,\n",
    "    image_prompts=image_prompts,\n",
    "    masks=masks,\n",
    "    sigma_range=(1.0, 0.5),   #     00.5\n",
    "    guidance_scale=7.5,\n",
    "    num_inference_steps=30,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# 6.  \n",
    "for i, im in enumerate(images):\n",
    "    im.save(f\"output_{i}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
