{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bde59470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "from transformers import CLIPTokenizer, CLIPTextModel\n",
    "from torchvision import transforms\n",
    "from transformers import CLIPImageProcessor\n",
    "from PIL import Image\n",
    "from diffusers.models.attention import Attention as CrossAttention\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from safetensors.torch import safe_open\n",
    "from transformers import CLIPVisionModelWithProjection, CLIPImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f4d33de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProjModel(torch.nn.Module):\n",
    "    \"\"\"Projection Model\"\"\"\n",
    "\n",
    "    def __init__(self, cross_attention_dim=1024, clip_embeddings_dim=1024, clip_extra_context_tokens=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.generator = None\n",
    "        self.cross_attention_dim = cross_attention_dim\n",
    "        self.clip_extra_context_tokens = clip_extra_context_tokens\n",
    "        self.proj = torch.nn.Linear(clip_embeddings_dim, self.clip_extra_context_tokens * cross_attention_dim)\n",
    "        self.norm = torch.nn.LayerNorm(cross_attention_dim)\n",
    "\n",
    "    def forward(self, image_embeds):\n",
    "        embeds = image_embeds\n",
    "        clip_extra_context_tokens = self.proj(embeds).reshape(\n",
    "            -1, self.clip_extra_context_tokens, self.cross_attention_dim\n",
    "        )\n",
    "        clip_extra_context_tokens = self.norm(clip_extra_context_tokens)\n",
    "        return clip_extra_context_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51b25c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPAdapterModule:\n",
    "    def __init__(self, image_encoder_path, ip_ckpt, device, num_tokens=4, cross_attention_dim=768):\n",
    "        self.device = device\n",
    "        self.image_encoder_path = image_encoder_path\n",
    "        self.ip_ckpt = ip_ckpt\n",
    "        self.num_tokens = num_tokens\n",
    "        self.cross_attention_dim = cross_attention_dim\n",
    "\n",
    "        self.image_encoder = CLIPVisionModelWithProjection.from_pretrained(self.image_encoder_path).to(\n",
    "            self.device, dtype=torch.float16\n",
    "        )\n",
    "        self.clip_image_processor = CLIPImageProcessor()\n",
    "        self.image_proj_model = self.init_proj()\n",
    "        self.load_ip_adapter_weights()\n",
    "\n",
    "    def init_proj(self):# или путь к вашей реализации\n",
    "        image_proj_model = ImageProjModel(\n",
    "            cross_attention_dim=self.cross_attention_dim,\n",
    "            clip_embeddings_dim=self.image_encoder.config.projection_dim,\n",
    "            clip_extra_context_tokens=self.num_tokens,\n",
    "        ).to(self.device, dtype=torch.float16)\n",
    "        return image_proj_model\n",
    "\n",
    "    def load_ip_adapter_weights(self):\n",
    "        if os.path.splitext(self.ip_ckpt)[-1] == \".safetensors\":\n",
    "            state_dict = {\"image_proj\": {}, \"ip_adapter\": {}}\n",
    "            with safe_open(self.ip_ckpt, framework=\"pt\", device=\"cpu\") as f:\n",
    "                for key in f.keys():\n",
    "                    if key.startswith(\"image_proj.\"):\n",
    "                        state_dict[\"image_proj\"][key.replace(\"image_proj.\", \"\")] = f.get_tensor(key)\n",
    "                    elif key.startswith(\"ip_adapter.\"):\n",
    "                        state_dict[\"ip_adapter\"][key.replace(\"ip_adapter.\", \"\")] = f.get_tensor(key)\n",
    "        else:\n",
    "            state_dict = torch.load(self.ip_ckpt, map_location=\"cpu\")\n",
    "        self.image_proj_model.load_state_dict(state_dict[\"image_proj\"])\n",
    "        self._attn_weights = state_dict[\"ip_adapter\"]  # храним отдельно, применим в set_ip_adapter\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_image_embeds(self, pil_image=None, clip_image_embeds=None):\n",
    "        if pil_image is not None:\n",
    "            if isinstance(pil_image, Image.Image):\n",
    "                pil_image = [pil_image]\n",
    "            clip_image = self.clip_image_processor(images=pil_image, return_tensors=\"pt\").pixel_values\n",
    "            clip_image_embeds = self.image_encoder(clip_image.to(self.device, dtype=torch.float16)).image_embeds\n",
    "        else:\n",
    "            clip_image_embeds = clip_image_embeds.to(self.device, dtype=torch.float16)\n",
    "\n",
    "        image_prompt_embeds = self.image_proj_model(clip_image_embeds)\n",
    "        uncond_image_prompt_embeds = self.image_proj_model(torch.zeros_like(clip_image_embeds))\n",
    "        return image_prompt_embeds, uncond_image_prompt_embeds\n",
    "\n",
    "    def set_ip_adapter(self, unet):\n",
    "        from attention_processor import IPAttnProcessor, AttnProcessor  \n",
    "        attn_procs = {}\n",
    "        for name in unet.attn_processors.keys():\n",
    "            if name.endswith(\"attn1.processor\"):\n",
    "                attn_procs[name] = AttnProcessor()\n",
    "                continue\n",
    "\n",
    "            cross_attention_dim = self.cross_attention_dim\n",
    "            if name.startswith(\"mid_block\"):\n",
    "                hidden_size = unet.config.block_out_channels[-1]\n",
    "            elif name.startswith(\"up_blocks\"):\n",
    "                block_id = int(name[len(\"up_blocks.\")])\n",
    "                hidden_size = list(reversed(unet.config.block_out_channels))[block_id]\n",
    "            elif name.startswith(\"down_blocks\"):\n",
    "                block_id = int(name[len(\"down_blocks.\")])\n",
    "                hidden_size = unet.config.block_out_channels[block_id]\n",
    "\n",
    "            ip_proc = IPAttnProcessor(\n",
    "                hidden_size=hidden_size,\n",
    "                cross_attention_dim=cross_attention_dim,\n",
    "                scale=1.0,\n",
    "                num_tokens=self.num_tokens,\n",
    "            ).to(self.device, dtype=torch.float16)\n",
    "            attn_procs[name] = ip_proc\n",
    "\n",
    "        unet.set_attn_processor(attn_procs)\n",
    "\n",
    "        # загружаем веса IP-адаптера (после set_attn_processor)\n",
    "        ip_layers = torch.nn.ModuleList(unet.attn_processors.values())\n",
    "        ip_layers.load_state_dict(self._attn_weights)\n",
    "\n",
    "    def set_scale(self, unet, scale):\n",
    "        for attn_proc in unet.attn_processors.values():\n",
    "            if hasattr(attn_proc, \"scale\"):\n",
    "                attn_proc.scale = scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad6a30c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3deaea0ef694d859773fe692e4de6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: ['conv_in.weight', 'conv_in.bias', 'time_embedding.linear_1.weight', 'time_embedding.linear_1.bias', 'time_embedding.linear_2.weight', 'time_embedding.linear_2.bias', 'down_blocks.0.attentions.0.norm.weight', 'down_blocks.0.attentions.0.norm.bias', 'down_blocks.0.attentions.0.proj_in.weight', 'down_blocks.0.attentions.0.proj_in.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.norm1.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.norm1.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.norm2.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.norm2.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.norm3.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.norm3.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.weight', 'down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.bias', 'down_blocks.0.attentions.0.proj_out.weight', 'down_blocks.0.attentions.0.proj_out.bias', 'down_blocks.0.attentions.1.norm.weight', 'down_blocks.0.attentions.1.norm.bias', 'down_blocks.0.attentions.1.proj_in.weight', 'down_blocks.0.attentions.1.proj_in.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.norm1.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.norm1.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.norm2.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.norm2.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.norm3.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.norm3.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.weight', 'down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.bias', 'down_blocks.0.attentions.1.proj_out.weight', 'down_blocks.0.attentions.1.proj_out.bias', 'down_blocks.0.resnets.0.norm1.weight', 'down_blocks.0.resnets.0.norm1.bias', 'down_blocks.0.resnets.0.conv1.weight', 'down_blocks.0.resnets.0.conv1.bias', 'down_blocks.0.resnets.0.time_emb_proj.weight', 'down_blocks.0.resnets.0.time_emb_proj.bias', 'down_blocks.0.resnets.0.norm2.weight', 'down_blocks.0.resnets.0.norm2.bias', 'down_blocks.0.resnets.0.conv2.weight', 'down_blocks.0.resnets.0.conv2.bias', 'down_blocks.0.resnets.1.norm1.weight', 'down_blocks.0.resnets.1.norm1.bias', 'down_blocks.0.resnets.1.conv1.weight', 'down_blocks.0.resnets.1.conv1.bias', 'down_blocks.0.resnets.1.time_emb_proj.weight', 'down_blocks.0.resnets.1.time_emb_proj.bias', 'down_blocks.0.resnets.1.norm2.weight', 'down_blocks.0.resnets.1.norm2.bias', 'down_blocks.0.resnets.1.conv2.weight', 'down_blocks.0.resnets.1.conv2.bias', 'down_blocks.0.downsamplers.0.conv.weight', 'down_blocks.0.downsamplers.0.conv.bias', 'down_blocks.1.attentions.0.norm.weight', 'down_blocks.1.attentions.0.norm.bias', 'down_blocks.1.attentions.0.proj_in.weight', 'down_blocks.1.attentions.0.proj_in.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.norm1.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.norm1.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.norm2.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.norm2.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.norm3.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.norm3.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight', 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias', 'down_blocks.1.attentions.0.proj_out.weight', 'down_blocks.1.attentions.0.proj_out.bias', 'down_blocks.1.attentions.1.norm.weight', 'down_blocks.1.attentions.1.norm.bias', 'down_blocks.1.attentions.1.proj_in.weight', 'down_blocks.1.attentions.1.proj_in.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.norm1.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.norm1.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.norm2.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.norm2.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.norm3.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.norm3.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight', 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias', 'down_blocks.1.attentions.1.proj_out.weight', 'down_blocks.1.attentions.1.proj_out.bias', 'down_blocks.1.resnets.0.norm1.weight', 'down_blocks.1.resnets.0.norm1.bias', 'down_blocks.1.resnets.0.conv1.weight', 'down_blocks.1.resnets.0.conv1.bias', 'down_blocks.1.resnets.0.time_emb_proj.weight', 'down_blocks.1.resnets.0.time_emb_proj.bias', 'down_blocks.1.resnets.0.norm2.weight', 'down_blocks.1.resnets.0.norm2.bias', 'down_blocks.1.resnets.0.conv2.weight', 'down_blocks.1.resnets.0.conv2.bias', 'down_blocks.1.resnets.0.conv_shortcut.weight', 'down_blocks.1.resnets.0.conv_shortcut.bias', 'down_blocks.1.resnets.1.norm1.weight', 'down_blocks.1.resnets.1.norm1.bias', 'down_blocks.1.resnets.1.conv1.weight', 'down_blocks.1.resnets.1.conv1.bias', 'down_blocks.1.resnets.1.time_emb_proj.weight', 'down_blocks.1.resnets.1.time_emb_proj.bias', 'down_blocks.1.resnets.1.norm2.weight', 'down_blocks.1.resnets.1.norm2.bias', 'down_blocks.1.resnets.1.conv2.weight', 'down_blocks.1.resnets.1.conv2.bias', 'down_blocks.1.downsamplers.0.conv.weight', 'down_blocks.1.downsamplers.0.conv.bias', 'down_blocks.2.attentions.0.norm.weight', 'down_blocks.2.attentions.0.norm.bias', 'down_blocks.2.attentions.0.proj_in.weight', 'down_blocks.2.attentions.0.proj_in.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.norm1.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.norm1.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.norm2.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.norm2.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.norm3.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.norm3.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight', 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias', 'down_blocks.2.attentions.0.proj_out.weight', 'down_blocks.2.attentions.0.proj_out.bias', 'down_blocks.2.attentions.1.norm.weight', 'down_blocks.2.attentions.1.norm.bias', 'down_blocks.2.attentions.1.proj_in.weight', 'down_blocks.2.attentions.1.proj_in.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.norm1.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.norm1.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.norm2.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.norm2.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.norm3.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.norm3.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight', 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias', 'down_blocks.2.attentions.1.proj_out.weight', 'down_blocks.2.attentions.1.proj_out.bias', 'down_blocks.2.resnets.0.norm1.weight', 'down_blocks.2.resnets.0.norm1.bias', 'down_blocks.2.resnets.0.conv1.weight', 'down_blocks.2.resnets.0.conv1.bias', 'down_blocks.2.resnets.0.time_emb_proj.weight', 'down_blocks.2.resnets.0.time_emb_proj.bias', 'down_blocks.2.resnets.0.norm2.weight', 'down_blocks.2.resnets.0.norm2.bias', 'down_blocks.2.resnets.0.conv2.weight', 'down_blocks.2.resnets.0.conv2.bias', 'down_blocks.2.resnets.0.conv_shortcut.weight', 'down_blocks.2.resnets.0.conv_shortcut.bias', 'down_blocks.2.resnets.1.norm1.weight', 'down_blocks.2.resnets.1.norm1.bias', 'down_blocks.2.resnets.1.conv1.weight', 'down_blocks.2.resnets.1.conv1.bias', 'down_blocks.2.resnets.1.time_emb_proj.weight', 'down_blocks.2.resnets.1.time_emb_proj.bias', 'down_blocks.2.resnets.1.norm2.weight', 'down_blocks.2.resnets.1.norm2.bias', 'down_blocks.2.resnets.1.conv2.weight', 'down_blocks.2.resnets.1.conv2.bias', 'down_blocks.2.downsamplers.0.conv.weight', 'down_blocks.2.downsamplers.0.conv.bias', 'down_blocks.3.resnets.0.norm1.weight', 'down_blocks.3.resnets.0.norm1.bias', 'down_blocks.3.resnets.0.conv1.weight', 'down_blocks.3.resnets.0.conv1.bias', 'down_blocks.3.resnets.0.time_emb_proj.weight', 'down_blocks.3.resnets.0.time_emb_proj.bias', 'down_blocks.3.resnets.0.norm2.weight', 'down_blocks.3.resnets.0.norm2.bias', 'down_blocks.3.resnets.0.conv2.weight', 'down_blocks.3.resnets.0.conv2.bias', 'down_blocks.3.resnets.1.norm1.weight', 'down_blocks.3.resnets.1.norm1.bias', 'down_blocks.3.resnets.1.conv1.weight', 'down_blocks.3.resnets.1.conv1.bias', 'down_blocks.3.resnets.1.time_emb_proj.weight', 'down_blocks.3.resnets.1.time_emb_proj.bias', 'down_blocks.3.resnets.1.norm2.weight', 'down_blocks.3.resnets.1.norm2.bias', 'down_blocks.3.resnets.1.conv2.weight', 'down_blocks.3.resnets.1.conv2.bias', 'up_blocks.0.resnets.0.norm1.weight', 'up_blocks.0.resnets.0.norm1.bias', 'up_blocks.0.resnets.0.conv1.weight', 'up_blocks.0.resnets.0.conv1.bias', 'up_blocks.0.resnets.0.time_emb_proj.weight', 'up_blocks.0.resnets.0.time_emb_proj.bias', 'up_blocks.0.resnets.0.norm2.weight', 'up_blocks.0.resnets.0.norm2.bias', 'up_blocks.0.resnets.0.conv2.weight', 'up_blocks.0.resnets.0.conv2.bias', 'up_blocks.0.resnets.0.conv_shortcut.weight', 'up_blocks.0.resnets.0.conv_shortcut.bias', 'up_blocks.0.resnets.1.norm1.weight', 'up_blocks.0.resnets.1.norm1.bias', 'up_blocks.0.resnets.1.conv1.weight', 'up_blocks.0.resnets.1.conv1.bias', 'up_blocks.0.resnets.1.time_emb_proj.weight', 'up_blocks.0.resnets.1.time_emb_proj.bias', 'up_blocks.0.resnets.1.norm2.weight', 'up_blocks.0.resnets.1.norm2.bias', 'up_blocks.0.resnets.1.conv2.weight', 'up_blocks.0.resnets.1.conv2.bias', 'up_blocks.0.resnets.1.conv_shortcut.weight', 'up_blocks.0.resnets.1.conv_shortcut.bias', 'up_blocks.0.resnets.2.norm1.weight', 'up_blocks.0.resnets.2.norm1.bias', 'up_blocks.0.resnets.2.conv1.weight', 'up_blocks.0.resnets.2.conv1.bias', 'up_blocks.0.resnets.2.time_emb_proj.weight', 'up_blocks.0.resnets.2.time_emb_proj.bias', 'up_blocks.0.resnets.2.norm2.weight', 'up_blocks.0.resnets.2.norm2.bias', 'up_blocks.0.resnets.2.conv2.weight', 'up_blocks.0.resnets.2.conv2.bias', 'up_blocks.0.resnets.2.conv_shortcut.weight', 'up_blocks.0.resnets.2.conv_shortcut.bias', 'up_blocks.0.upsamplers.0.conv.weight', 'up_blocks.0.upsamplers.0.conv.bias', 'up_blocks.1.attentions.0.norm.weight', 'up_blocks.1.attentions.0.norm.bias', 'up_blocks.1.attentions.0.proj_in.weight', 'up_blocks.1.attentions.0.proj_in.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.norm1.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.norm1.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.norm2.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.norm2.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.norm3.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.norm3.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight', 'up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias', 'up_blocks.1.attentions.0.proj_out.weight', 'up_blocks.1.attentions.0.proj_out.bias', 'up_blocks.1.attentions.1.norm.weight', 'up_blocks.1.attentions.1.norm.bias', 'up_blocks.1.attentions.1.proj_in.weight', 'up_blocks.1.attentions.1.proj_in.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.norm1.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.norm1.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.norm2.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.norm2.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.norm3.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.norm3.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight', 'up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias', 'up_blocks.1.attentions.1.proj_out.weight', 'up_blocks.1.attentions.1.proj_out.bias', 'up_blocks.1.attentions.2.norm.weight', 'up_blocks.1.attentions.2.norm.bias', 'up_blocks.1.attentions.2.proj_in.weight', 'up_blocks.1.attentions.2.proj_in.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.norm1.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.norm1.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.norm2.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.norm2.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.norm3.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.norm3.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.weight', 'up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.bias', 'up_blocks.1.attentions.2.proj_out.weight', 'up_blocks.1.attentions.2.proj_out.bias', 'up_blocks.1.resnets.0.norm1.weight', 'up_blocks.1.resnets.0.norm1.bias', 'up_blocks.1.resnets.0.conv1.weight', 'up_blocks.1.resnets.0.conv1.bias', 'up_blocks.1.resnets.0.time_emb_proj.weight', 'up_blocks.1.resnets.0.time_emb_proj.bias', 'up_blocks.1.resnets.0.norm2.weight', 'up_blocks.1.resnets.0.norm2.bias', 'up_blocks.1.resnets.0.conv2.weight', 'up_blocks.1.resnets.0.conv2.bias', 'up_blocks.1.resnets.0.conv_shortcut.weight', 'up_blocks.1.resnets.0.conv_shortcut.bias', 'up_blocks.1.resnets.1.norm1.weight', 'up_blocks.1.resnets.1.norm1.bias', 'up_blocks.1.resnets.1.conv1.weight', 'up_blocks.1.resnets.1.conv1.bias', 'up_blocks.1.resnets.1.time_emb_proj.weight', 'up_blocks.1.resnets.1.time_emb_proj.bias', 'up_blocks.1.resnets.1.norm2.weight', 'up_blocks.1.resnets.1.norm2.bias', 'up_blocks.1.resnets.1.conv2.weight', 'up_blocks.1.resnets.1.conv2.bias', 'up_blocks.1.resnets.1.conv_shortcut.weight', 'up_blocks.1.resnets.1.conv_shortcut.bias', 'up_blocks.1.resnets.2.norm1.weight', 'up_blocks.1.resnets.2.norm1.bias', 'up_blocks.1.resnets.2.conv1.weight', 'up_blocks.1.resnets.2.conv1.bias', 'up_blocks.1.resnets.2.time_emb_proj.weight', 'up_blocks.1.resnets.2.time_emb_proj.bias', 'up_blocks.1.resnets.2.norm2.weight', 'up_blocks.1.resnets.2.norm2.bias', 'up_blocks.1.resnets.2.conv2.weight', 'up_blocks.1.resnets.2.conv2.bias', 'up_blocks.1.resnets.2.conv_shortcut.weight', 'up_blocks.1.resnets.2.conv_shortcut.bias', 'up_blocks.1.upsamplers.0.conv.weight', 'up_blocks.1.upsamplers.0.conv.bias', 'up_blocks.2.attentions.0.norm.weight', 'up_blocks.2.attentions.0.norm.bias', 'up_blocks.2.attentions.0.proj_in.weight', 'up_blocks.2.attentions.0.proj_in.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.norm1.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.norm1.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.norm2.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.norm2.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.norm3.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.norm3.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight', 'up_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias', 'up_blocks.2.attentions.0.proj_out.weight', 'up_blocks.2.attentions.0.proj_out.bias', 'up_blocks.2.attentions.1.norm.weight', 'up_blocks.2.attentions.1.norm.bias', 'up_blocks.2.attentions.1.proj_in.weight', 'up_blocks.2.attentions.1.proj_in.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.norm1.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.norm1.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.norm2.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.norm2.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.norm3.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.norm3.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight', 'up_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias', 'up_blocks.2.attentions.1.proj_out.weight', 'up_blocks.2.attentions.1.proj_out.bias', 'up_blocks.2.attentions.2.norm.weight', 'up_blocks.2.attentions.2.norm.bias', 'up_blocks.2.attentions.2.proj_in.weight', 'up_blocks.2.attentions.2.proj_in.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.norm1.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.norm1.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.norm2.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.norm2.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.norm3.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.norm3.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.2.attentions.2.transformer_blocks.0.ff.net.2.weight', 'up_blocks.2.attentions.2.transformer_blocks.0.ff.net.2.bias', 'up_blocks.2.attentions.2.proj_out.weight', 'up_blocks.2.attentions.2.proj_out.bias', 'up_blocks.2.resnets.0.norm1.weight', 'up_blocks.2.resnets.0.norm1.bias', 'up_blocks.2.resnets.0.conv1.weight', 'up_blocks.2.resnets.0.conv1.bias', 'up_blocks.2.resnets.0.time_emb_proj.weight', 'up_blocks.2.resnets.0.time_emb_proj.bias', 'up_blocks.2.resnets.0.norm2.weight', 'up_blocks.2.resnets.0.norm2.bias', 'up_blocks.2.resnets.0.conv2.weight', 'up_blocks.2.resnets.0.conv2.bias', 'up_blocks.2.resnets.0.conv_shortcut.weight', 'up_blocks.2.resnets.0.conv_shortcut.bias', 'up_blocks.2.resnets.1.norm1.weight', 'up_blocks.2.resnets.1.norm1.bias', 'up_blocks.2.resnets.1.conv1.weight', 'up_blocks.2.resnets.1.conv1.bias', 'up_blocks.2.resnets.1.time_emb_proj.weight', 'up_blocks.2.resnets.1.time_emb_proj.bias', 'up_blocks.2.resnets.1.norm2.weight', 'up_blocks.2.resnets.1.norm2.bias', 'up_blocks.2.resnets.1.conv2.weight', 'up_blocks.2.resnets.1.conv2.bias', 'up_blocks.2.resnets.1.conv_shortcut.weight', 'up_blocks.2.resnets.1.conv_shortcut.bias', 'up_blocks.2.resnets.2.norm1.weight', 'up_blocks.2.resnets.2.norm1.bias', 'up_blocks.2.resnets.2.conv1.weight', 'up_blocks.2.resnets.2.conv1.bias', 'up_blocks.2.resnets.2.time_emb_proj.weight', 'up_blocks.2.resnets.2.time_emb_proj.bias', 'up_blocks.2.resnets.2.norm2.weight', 'up_blocks.2.resnets.2.norm2.bias', 'up_blocks.2.resnets.2.conv2.weight', 'up_blocks.2.resnets.2.conv2.bias', 'up_blocks.2.resnets.2.conv_shortcut.weight', 'up_blocks.2.resnets.2.conv_shortcut.bias', 'up_blocks.2.upsamplers.0.conv.weight', 'up_blocks.2.upsamplers.0.conv.bias', 'up_blocks.3.attentions.0.norm.weight', 'up_blocks.3.attentions.0.norm.bias', 'up_blocks.3.attentions.0.proj_in.weight', 'up_blocks.3.attentions.0.proj_in.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.norm1.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.norm1.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.norm2.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.norm2.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.norm3.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.norm3.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.3.attentions.0.transformer_blocks.0.ff.net.2.weight', 'up_blocks.3.attentions.0.transformer_blocks.0.ff.net.2.bias', 'up_blocks.3.attentions.0.proj_out.weight', 'up_blocks.3.attentions.0.proj_out.bias', 'up_blocks.3.attentions.1.norm.weight', 'up_blocks.3.attentions.1.norm.bias', 'up_blocks.3.attentions.1.proj_in.weight', 'up_blocks.3.attentions.1.proj_in.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.norm1.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.norm1.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.norm2.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.norm2.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.norm3.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.norm3.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.3.attentions.1.transformer_blocks.0.ff.net.2.weight', 'up_blocks.3.attentions.1.transformer_blocks.0.ff.net.2.bias', 'up_blocks.3.attentions.1.proj_out.weight', 'up_blocks.3.attentions.1.proj_out.bias', 'up_blocks.3.attentions.2.norm.weight', 'up_blocks.3.attentions.2.norm.bias', 'up_blocks.3.attentions.2.proj_in.weight', 'up_blocks.3.attentions.2.proj_in.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.norm1.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.norm1.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_q.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_k.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_v.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_out.0.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_out.0.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.norm2.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.norm2.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_q.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_k.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_v.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.norm3.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.norm3.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.ff.net.0.proj.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.ff.net.0.proj.bias', 'up_blocks.3.attentions.2.transformer_blocks.0.ff.net.2.weight', 'up_blocks.3.attentions.2.transformer_blocks.0.ff.net.2.bias', 'up_blocks.3.attentions.2.proj_out.weight', 'up_blocks.3.attentions.2.proj_out.bias', 'up_blocks.3.resnets.0.norm1.weight', 'up_blocks.3.resnets.0.norm1.bias', 'up_blocks.3.resnets.0.conv1.weight', 'up_blocks.3.resnets.0.conv1.bias', 'up_blocks.3.resnets.0.time_emb_proj.weight', 'up_blocks.3.resnets.0.time_emb_proj.bias', 'up_blocks.3.resnets.0.norm2.weight', 'up_blocks.3.resnets.0.norm2.bias', 'up_blocks.3.resnets.0.conv2.weight', 'up_blocks.3.resnets.0.conv2.bias', 'up_blocks.3.resnets.0.conv_shortcut.weight', 'up_blocks.3.resnets.0.conv_shortcut.bias', 'up_blocks.3.resnets.1.norm1.weight', 'up_blocks.3.resnets.1.norm1.bias', 'up_blocks.3.resnets.1.conv1.weight', 'up_blocks.3.resnets.1.conv1.bias', 'up_blocks.3.resnets.1.time_emb_proj.weight', 'up_blocks.3.resnets.1.time_emb_proj.bias', 'up_blocks.3.resnets.1.norm2.weight', 'up_blocks.3.resnets.1.norm2.bias', 'up_blocks.3.resnets.1.conv2.weight', 'up_blocks.3.resnets.1.conv2.bias', 'up_blocks.3.resnets.1.conv_shortcut.weight', 'up_blocks.3.resnets.1.conv_shortcut.bias', 'up_blocks.3.resnets.2.norm1.weight', 'up_blocks.3.resnets.2.norm1.bias', 'up_blocks.3.resnets.2.conv1.weight', 'up_blocks.3.resnets.2.conv1.bias', 'up_blocks.3.resnets.2.time_emb_proj.weight', 'up_blocks.3.resnets.2.time_emb_proj.bias', 'up_blocks.3.resnets.2.norm2.weight', 'up_blocks.3.resnets.2.norm2.bias', 'up_blocks.3.resnets.2.conv2.weight', 'up_blocks.3.resnets.2.conv2.bias', 'up_blocks.3.resnets.2.conv_shortcut.weight', 'up_blocks.3.resnets.2.conv_shortcut.bias', 'mid_block.attentions.0.norm.weight', 'mid_block.attentions.0.norm.bias', 'mid_block.attentions.0.proj_in.weight', 'mid_block.attentions.0.proj_in.bias', 'mid_block.attentions.0.transformer_blocks.0.norm1.weight', 'mid_block.attentions.0.transformer_blocks.0.norm1.bias', 'mid_block.attentions.0.transformer_blocks.0.attn1.to_q.weight', 'mid_block.attentions.0.transformer_blocks.0.attn1.to_k.weight', 'mid_block.attentions.0.transformer_blocks.0.attn1.to_v.weight', 'mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.weight', 'mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.bias', 'mid_block.attentions.0.transformer_blocks.0.norm2.weight', 'mid_block.attentions.0.transformer_blocks.0.norm2.bias', 'mid_block.attentions.0.transformer_blocks.0.attn2.to_q.weight', 'mid_block.attentions.0.transformer_blocks.0.attn2.to_k.weight', 'mid_block.attentions.0.transformer_blocks.0.attn2.to_v.weight', 'mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.weight', 'mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.bias', 'mid_block.attentions.0.transformer_blocks.0.norm3.weight', 'mid_block.attentions.0.transformer_blocks.0.norm3.bias', 'mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.weight', 'mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.bias', 'mid_block.attentions.0.transformer_blocks.0.ff.net.2.weight', 'mid_block.attentions.0.transformer_blocks.0.ff.net.2.bias', 'mid_block.attentions.0.proj_out.weight', 'mid_block.attentions.0.proj_out.bias', 'mid_block.resnets.0.norm1.weight', 'mid_block.resnets.0.norm1.bias', 'mid_block.resnets.0.conv1.weight', 'mid_block.resnets.0.conv1.bias', 'mid_block.resnets.0.time_emb_proj.weight', 'mid_block.resnets.0.time_emb_proj.bias', 'mid_block.resnets.0.norm2.weight', 'mid_block.resnets.0.norm2.bias', 'mid_block.resnets.0.conv2.weight', 'mid_block.resnets.0.conv2.bias', 'mid_block.resnets.1.norm1.weight', 'mid_block.resnets.1.norm1.bias', 'mid_block.resnets.1.conv1.weight', 'mid_block.resnets.1.conv1.bias', 'mid_block.resnets.1.time_emb_proj.weight', 'mid_block.resnets.1.time_emb_proj.bias', 'mid_block.resnets.1.norm2.weight', 'mid_block.resnets.1.norm2.bias', 'mid_block.resnets.1.conv2.weight', 'mid_block.resnets.1.conv2.bias', 'conv_norm_out.weight', 'conv_norm_out.bias', 'conv_out.weight', 'conv_out.bias'], Unexpected: ['input_blocks.0.0.bias', 'input_blocks.0.0.weight', 'input_blocks.1.0.emb_layers.1.bias', 'input_blocks.1.0.emb_layers.1.weight', 'input_blocks.1.0.in_layers.0.bias', 'input_blocks.1.0.in_layers.0.weight', 'input_blocks.1.0.in_layers.2.bias', 'input_blocks.1.0.in_layers.2.weight', 'input_blocks.1.0.out_layers.0.bias', 'input_blocks.1.0.out_layers.0.weight', 'input_blocks.1.0.out_layers.3.bias', 'input_blocks.1.0.out_layers.3.weight', 'input_blocks.1.1.norm.bias', 'input_blocks.1.1.norm.weight', 'input_blocks.1.1.proj_in.bias', 'input_blocks.1.1.proj_in.weight', 'input_blocks.1.1.proj_out.bias', 'input_blocks.1.1.proj_out.weight', 'input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight', 'input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias', 'input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight', 'input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight', 'input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight', 'input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight', 'input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias', 'input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight', 'input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight', 'input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight', 'input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias', 'input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight', 'input_blocks.1.1.transformer_blocks.0.ff.net.2.bias', 'input_blocks.1.1.transformer_blocks.0.ff.net.2.weight', 'input_blocks.1.1.transformer_blocks.0.norm1.bias', 'input_blocks.1.1.transformer_blocks.0.norm1.weight', 'input_blocks.1.1.transformer_blocks.0.norm2.bias', 'input_blocks.1.1.transformer_blocks.0.norm2.weight', 'input_blocks.1.1.transformer_blocks.0.norm3.bias', 'input_blocks.1.1.transformer_blocks.0.norm3.weight', 'input_blocks.10.0.emb_layers.1.bias', 'input_blocks.10.0.emb_layers.1.weight', 'input_blocks.10.0.in_layers.0.bias', 'input_blocks.10.0.in_layers.0.weight', 'input_blocks.10.0.in_layers.2.bias', 'input_blocks.10.0.in_layers.2.weight', 'input_blocks.10.0.out_layers.0.bias', 'input_blocks.10.0.out_layers.0.weight', 'input_blocks.10.0.out_layers.3.bias', 'input_blocks.10.0.out_layers.3.weight', 'input_blocks.11.0.emb_layers.1.bias', 'input_blocks.11.0.emb_layers.1.weight', 'input_blocks.11.0.in_layers.0.bias', 'input_blocks.11.0.in_layers.0.weight', 'input_blocks.11.0.in_layers.2.bias', 'input_blocks.11.0.in_layers.2.weight', 'input_blocks.11.0.out_layers.0.bias', 'input_blocks.11.0.out_layers.0.weight', 'input_blocks.11.0.out_layers.3.bias', 'input_blocks.11.0.out_layers.3.weight', 'input_blocks.2.0.emb_layers.1.bias', 'input_blocks.2.0.emb_layers.1.weight', 'input_blocks.2.0.in_layers.0.bias', 'input_blocks.2.0.in_layers.0.weight', 'input_blocks.2.0.in_layers.2.bias', 'input_blocks.2.0.in_layers.2.weight', 'input_blocks.2.0.out_layers.0.bias', 'input_blocks.2.0.out_layers.0.weight', 'input_blocks.2.0.out_layers.3.bias', 'input_blocks.2.0.out_layers.3.weight', 'input_blocks.2.1.norm.bias', 'input_blocks.2.1.norm.weight', 'input_blocks.2.1.proj_in.bias', 'input_blocks.2.1.proj_in.weight', 'input_blocks.2.1.proj_out.bias', 'input_blocks.2.1.proj_out.weight', 'input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight', 'input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias', 'input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight', 'input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight', 'input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight', 'input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight', 'input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias', 'input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight', 'input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight', 'input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight', 'input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias', 'input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight', 'input_blocks.2.1.transformer_blocks.0.ff.net.2.bias', 'input_blocks.2.1.transformer_blocks.0.ff.net.2.weight', 'input_blocks.2.1.transformer_blocks.0.norm1.bias', 'input_blocks.2.1.transformer_blocks.0.norm1.weight', 'input_blocks.2.1.transformer_blocks.0.norm2.bias', 'input_blocks.2.1.transformer_blocks.0.norm2.weight', 'input_blocks.2.1.transformer_blocks.0.norm3.bias', 'input_blocks.2.1.transformer_blocks.0.norm3.weight', 'input_blocks.3.0.op.bias', 'input_blocks.3.0.op.weight', 'input_blocks.4.0.emb_layers.1.bias', 'input_blocks.4.0.emb_layers.1.weight', 'input_blocks.4.0.in_layers.0.bias', 'input_blocks.4.0.in_layers.0.weight', 'input_blocks.4.0.in_layers.2.bias', 'input_blocks.4.0.in_layers.2.weight', 'input_blocks.4.0.out_layers.0.bias', 'input_blocks.4.0.out_layers.0.weight', 'input_blocks.4.0.out_layers.3.bias', 'input_blocks.4.0.out_layers.3.weight', 'input_blocks.4.0.skip_connection.bias', 'input_blocks.4.0.skip_connection.weight', 'input_blocks.4.1.norm.bias', 'input_blocks.4.1.norm.weight', 'input_blocks.4.1.proj_in.bias', 'input_blocks.4.1.proj_in.weight', 'input_blocks.4.1.proj_out.bias', 'input_blocks.4.1.proj_out.weight', 'input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'input_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'input_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'input_blocks.4.1.transformer_blocks.0.norm1.bias', 'input_blocks.4.1.transformer_blocks.0.norm1.weight', 'input_blocks.4.1.transformer_blocks.0.norm2.bias', 'input_blocks.4.1.transformer_blocks.0.norm2.weight', 'input_blocks.4.1.transformer_blocks.0.norm3.bias', 'input_blocks.4.1.transformer_blocks.0.norm3.weight', 'input_blocks.5.0.emb_layers.1.bias', 'input_blocks.5.0.emb_layers.1.weight', 'input_blocks.5.0.in_layers.0.bias', 'input_blocks.5.0.in_layers.0.weight', 'input_blocks.5.0.in_layers.2.bias', 'input_blocks.5.0.in_layers.2.weight', 'input_blocks.5.0.out_layers.0.bias', 'input_blocks.5.0.out_layers.0.weight', 'input_blocks.5.0.out_layers.3.bias', 'input_blocks.5.0.out_layers.3.weight', 'input_blocks.5.1.norm.bias', 'input_blocks.5.1.norm.weight', 'input_blocks.5.1.proj_in.bias', 'input_blocks.5.1.proj_in.weight', 'input_blocks.5.1.proj_out.bias', 'input_blocks.5.1.proj_out.weight', 'input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'input_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'input_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'input_blocks.5.1.transformer_blocks.0.norm1.bias', 'input_blocks.5.1.transformer_blocks.0.norm1.weight', 'input_blocks.5.1.transformer_blocks.0.norm2.bias', 'input_blocks.5.1.transformer_blocks.0.norm2.weight', 'input_blocks.5.1.transformer_blocks.0.norm3.bias', 'input_blocks.5.1.transformer_blocks.0.norm3.weight', 'input_blocks.6.0.op.bias', 'input_blocks.6.0.op.weight', 'input_blocks.7.0.emb_layers.1.bias', 'input_blocks.7.0.emb_layers.1.weight', 'input_blocks.7.0.in_layers.0.bias', 'input_blocks.7.0.in_layers.0.weight', 'input_blocks.7.0.in_layers.2.bias', 'input_blocks.7.0.in_layers.2.weight', 'input_blocks.7.0.out_layers.0.bias', 'input_blocks.7.0.out_layers.0.weight', 'input_blocks.7.0.out_layers.3.bias', 'input_blocks.7.0.out_layers.3.weight', 'input_blocks.7.0.skip_connection.bias', 'input_blocks.7.0.skip_connection.weight', 'input_blocks.7.1.norm.bias', 'input_blocks.7.1.norm.weight', 'input_blocks.7.1.proj_in.bias', 'input_blocks.7.1.proj_in.weight', 'input_blocks.7.1.proj_out.bias', 'input_blocks.7.1.proj_out.weight', 'input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'input_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'input_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'input_blocks.7.1.transformer_blocks.0.norm1.bias', 'input_blocks.7.1.transformer_blocks.0.norm1.weight', 'input_blocks.7.1.transformer_blocks.0.norm2.bias', 'input_blocks.7.1.transformer_blocks.0.norm2.weight', 'input_blocks.7.1.transformer_blocks.0.norm3.bias', 'input_blocks.7.1.transformer_blocks.0.norm3.weight', 'input_blocks.8.0.emb_layers.1.bias', 'input_blocks.8.0.emb_layers.1.weight', 'input_blocks.8.0.in_layers.0.bias', 'input_blocks.8.0.in_layers.0.weight', 'input_blocks.8.0.in_layers.2.bias', 'input_blocks.8.0.in_layers.2.weight', 'input_blocks.8.0.out_layers.0.bias', 'input_blocks.8.0.out_layers.0.weight', 'input_blocks.8.0.out_layers.3.bias', 'input_blocks.8.0.out_layers.3.weight', 'input_blocks.8.1.norm.bias', 'input_blocks.8.1.norm.weight', 'input_blocks.8.1.proj_in.bias', 'input_blocks.8.1.proj_in.weight', 'input_blocks.8.1.proj_out.bias', 'input_blocks.8.1.proj_out.weight', 'input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'input_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'input_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'input_blocks.8.1.transformer_blocks.0.norm1.bias', 'input_blocks.8.1.transformer_blocks.0.norm1.weight', 'input_blocks.8.1.transformer_blocks.0.norm2.bias', 'input_blocks.8.1.transformer_blocks.0.norm2.weight', 'input_blocks.8.1.transformer_blocks.0.norm3.bias', 'input_blocks.8.1.transformer_blocks.0.norm3.weight', 'input_blocks.9.0.op.bias', 'input_blocks.9.0.op.weight', 'middle_block.0.emb_layers.1.bias', 'middle_block.0.emb_layers.1.weight', 'middle_block.0.in_layers.0.bias', 'middle_block.0.in_layers.0.weight', 'middle_block.0.in_layers.2.bias', 'middle_block.0.in_layers.2.weight', 'middle_block.0.out_layers.0.bias', 'middle_block.0.out_layers.0.weight', 'middle_block.0.out_layers.3.bias', 'middle_block.0.out_layers.3.weight', 'middle_block.1.norm.bias', 'middle_block.1.norm.weight', 'middle_block.1.proj_in.bias', 'middle_block.1.proj_in.weight', 'middle_block.1.proj_out.bias', 'middle_block.1.proj_out.weight', 'middle_block.1.transformer_blocks.0.attn1.to_k.weight', 'middle_block.1.transformer_blocks.0.attn1.to_out.0.bias', 'middle_block.1.transformer_blocks.0.attn1.to_out.0.weight', 'middle_block.1.transformer_blocks.0.attn1.to_q.weight', 'middle_block.1.transformer_blocks.0.attn1.to_v.weight', 'middle_block.1.transformer_blocks.0.attn2.to_k.weight', 'middle_block.1.transformer_blocks.0.attn2.to_out.0.bias', 'middle_block.1.transformer_blocks.0.attn2.to_out.0.weight', 'middle_block.1.transformer_blocks.0.attn2.to_q.weight', 'middle_block.1.transformer_blocks.0.attn2.to_v.weight', 'middle_block.1.transformer_blocks.0.ff.net.0.proj.bias', 'middle_block.1.transformer_blocks.0.ff.net.0.proj.weight', 'middle_block.1.transformer_blocks.0.ff.net.2.bias', 'middle_block.1.transformer_blocks.0.ff.net.2.weight', 'middle_block.1.transformer_blocks.0.norm1.bias', 'middle_block.1.transformer_blocks.0.norm1.weight', 'middle_block.1.transformer_blocks.0.norm2.bias', 'middle_block.1.transformer_blocks.0.norm2.weight', 'middle_block.1.transformer_blocks.0.norm3.bias', 'middle_block.1.transformer_blocks.0.norm3.weight', 'middle_block.2.emb_layers.1.bias', 'middle_block.2.emb_layers.1.weight', 'middle_block.2.in_layers.0.bias', 'middle_block.2.in_layers.0.weight', 'middle_block.2.in_layers.2.bias', 'middle_block.2.in_layers.2.weight', 'middle_block.2.out_layers.0.bias', 'middle_block.2.out_layers.0.weight', 'middle_block.2.out_layers.3.bias', 'middle_block.2.out_layers.3.weight', 'out.0.bias', 'out.0.weight', 'out.2.bias', 'out.2.weight', 'output_blocks.0.0.emb_layers.1.bias', 'output_blocks.0.0.emb_layers.1.weight', 'output_blocks.0.0.in_layers.0.bias', 'output_blocks.0.0.in_layers.0.weight', 'output_blocks.0.0.in_layers.2.bias', 'output_blocks.0.0.in_layers.2.weight', 'output_blocks.0.0.out_layers.0.bias', 'output_blocks.0.0.out_layers.0.weight', 'output_blocks.0.0.out_layers.3.bias', 'output_blocks.0.0.out_layers.3.weight', 'output_blocks.0.0.skip_connection.bias', 'output_blocks.0.0.skip_connection.weight', 'output_blocks.1.0.emb_layers.1.bias', 'output_blocks.1.0.emb_layers.1.weight', 'output_blocks.1.0.in_layers.0.bias', 'output_blocks.1.0.in_layers.0.weight', 'output_blocks.1.0.in_layers.2.bias', 'output_blocks.1.0.in_layers.2.weight', 'output_blocks.1.0.out_layers.0.bias', 'output_blocks.1.0.out_layers.0.weight', 'output_blocks.1.0.out_layers.3.bias', 'output_blocks.1.0.out_layers.3.weight', 'output_blocks.1.0.skip_connection.bias', 'output_blocks.1.0.skip_connection.weight', 'output_blocks.10.0.emb_layers.1.bias', 'output_blocks.10.0.emb_layers.1.weight', 'output_blocks.10.0.in_layers.0.bias', 'output_blocks.10.0.in_layers.0.weight', 'output_blocks.10.0.in_layers.2.bias', 'output_blocks.10.0.in_layers.2.weight', 'output_blocks.10.0.out_layers.0.bias', 'output_blocks.10.0.out_layers.0.weight', 'output_blocks.10.0.out_layers.3.bias', 'output_blocks.10.0.out_layers.3.weight', 'output_blocks.10.0.skip_connection.bias', 'output_blocks.10.0.skip_connection.weight', 'output_blocks.10.1.norm.bias', 'output_blocks.10.1.norm.weight', 'output_blocks.10.1.proj_in.bias', 'output_blocks.10.1.proj_in.weight', 'output_blocks.10.1.proj_out.bias', 'output_blocks.10.1.proj_out.weight', 'output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight', 'output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias', 'output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight', 'output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight', 'output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight', 'output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight', 'output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias', 'output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight', 'output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight', 'output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight', 'output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias', 'output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight', 'output_blocks.10.1.transformer_blocks.0.ff.net.2.bias', 'output_blocks.10.1.transformer_blocks.0.ff.net.2.weight', 'output_blocks.10.1.transformer_blocks.0.norm1.bias', 'output_blocks.10.1.transformer_blocks.0.norm1.weight', 'output_blocks.10.1.transformer_blocks.0.norm2.bias', 'output_blocks.10.1.transformer_blocks.0.norm2.weight', 'output_blocks.10.1.transformer_blocks.0.norm3.bias', 'output_blocks.10.1.transformer_blocks.0.norm3.weight', 'output_blocks.11.0.emb_layers.1.bias', 'output_blocks.11.0.emb_layers.1.weight', 'output_blocks.11.0.in_layers.0.bias', 'output_blocks.11.0.in_layers.0.weight', 'output_blocks.11.0.in_layers.2.bias', 'output_blocks.11.0.in_layers.2.weight', 'output_blocks.11.0.out_layers.0.bias', 'output_blocks.11.0.out_layers.0.weight', 'output_blocks.11.0.out_layers.3.bias', 'output_blocks.11.0.out_layers.3.weight', 'output_blocks.11.0.skip_connection.bias', 'output_blocks.11.0.skip_connection.weight', 'output_blocks.11.1.norm.bias', 'output_blocks.11.1.norm.weight', 'output_blocks.11.1.proj_in.bias', 'output_blocks.11.1.proj_in.weight', 'output_blocks.11.1.proj_out.bias', 'output_blocks.11.1.proj_out.weight', 'output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight', 'output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias', 'output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight', 'output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight', 'output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight', 'output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight', 'output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias', 'output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight', 'output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight', 'output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight', 'output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias', 'output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight', 'output_blocks.11.1.transformer_blocks.0.ff.net.2.bias', 'output_blocks.11.1.transformer_blocks.0.ff.net.2.weight', 'output_blocks.11.1.transformer_blocks.0.norm1.bias', 'output_blocks.11.1.transformer_blocks.0.norm1.weight', 'output_blocks.11.1.transformer_blocks.0.norm2.bias', 'output_blocks.11.1.transformer_blocks.0.norm2.weight', 'output_blocks.11.1.transformer_blocks.0.norm3.bias', 'output_blocks.11.1.transformer_blocks.0.norm3.weight', 'output_blocks.2.0.emb_layers.1.bias', 'output_blocks.2.0.emb_layers.1.weight', 'output_blocks.2.0.in_layers.0.bias', 'output_blocks.2.0.in_layers.0.weight', 'output_blocks.2.0.in_layers.2.bias', 'output_blocks.2.0.in_layers.2.weight', 'output_blocks.2.0.out_layers.0.bias', 'output_blocks.2.0.out_layers.0.weight', 'output_blocks.2.0.out_layers.3.bias', 'output_blocks.2.0.out_layers.3.weight', 'output_blocks.2.0.skip_connection.bias', 'output_blocks.2.0.skip_connection.weight', 'output_blocks.2.1.conv.bias', 'output_blocks.2.1.conv.weight', 'output_blocks.3.0.emb_layers.1.bias', 'output_blocks.3.0.emb_layers.1.weight', 'output_blocks.3.0.in_layers.0.bias', 'output_blocks.3.0.in_layers.0.weight', 'output_blocks.3.0.in_layers.2.bias', 'output_blocks.3.0.in_layers.2.weight', 'output_blocks.3.0.out_layers.0.bias', 'output_blocks.3.0.out_layers.0.weight', 'output_blocks.3.0.out_layers.3.bias', 'output_blocks.3.0.out_layers.3.weight', 'output_blocks.3.0.skip_connection.bias', 'output_blocks.3.0.skip_connection.weight', 'output_blocks.3.1.norm.bias', 'output_blocks.3.1.norm.weight', 'output_blocks.3.1.proj_in.bias', 'output_blocks.3.1.proj_in.weight', 'output_blocks.3.1.proj_out.bias', 'output_blocks.3.1.proj_out.weight', 'output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight', 'output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias', 'output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight', 'output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight', 'output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight', 'output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight', 'output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias', 'output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight', 'output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight', 'output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight', 'output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias', 'output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight', 'output_blocks.3.1.transformer_blocks.0.ff.net.2.bias', 'output_blocks.3.1.transformer_blocks.0.ff.net.2.weight', 'output_blocks.3.1.transformer_blocks.0.norm1.bias', 'output_blocks.3.1.transformer_blocks.0.norm1.weight', 'output_blocks.3.1.transformer_blocks.0.norm2.bias', 'output_blocks.3.1.transformer_blocks.0.norm2.weight', 'output_blocks.3.1.transformer_blocks.0.norm3.bias', 'output_blocks.3.1.transformer_blocks.0.norm3.weight', 'output_blocks.4.0.emb_layers.1.bias', 'output_blocks.4.0.emb_layers.1.weight', 'output_blocks.4.0.in_layers.0.bias', 'output_blocks.4.0.in_layers.0.weight', 'output_blocks.4.0.in_layers.2.bias', 'output_blocks.4.0.in_layers.2.weight', 'output_blocks.4.0.out_layers.0.bias', 'output_blocks.4.0.out_layers.0.weight', 'output_blocks.4.0.out_layers.3.bias', 'output_blocks.4.0.out_layers.3.weight', 'output_blocks.4.0.skip_connection.bias', 'output_blocks.4.0.skip_connection.weight', 'output_blocks.4.1.norm.bias', 'output_blocks.4.1.norm.weight', 'output_blocks.4.1.proj_in.bias', 'output_blocks.4.1.proj_in.weight', 'output_blocks.4.1.proj_out.bias', 'output_blocks.4.1.proj_out.weight', 'output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'output_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'output_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'output_blocks.4.1.transformer_blocks.0.norm1.bias', 'output_blocks.4.1.transformer_blocks.0.norm1.weight', 'output_blocks.4.1.transformer_blocks.0.norm2.bias', 'output_blocks.4.1.transformer_blocks.0.norm2.weight', 'output_blocks.4.1.transformer_blocks.0.norm3.bias', 'output_blocks.4.1.transformer_blocks.0.norm3.weight', 'output_blocks.5.0.emb_layers.1.bias', 'output_blocks.5.0.emb_layers.1.weight', 'output_blocks.5.0.in_layers.0.bias', 'output_blocks.5.0.in_layers.0.weight', 'output_blocks.5.0.in_layers.2.bias', 'output_blocks.5.0.in_layers.2.weight', 'output_blocks.5.0.out_layers.0.bias', 'output_blocks.5.0.out_layers.0.weight', 'output_blocks.5.0.out_layers.3.bias', 'output_blocks.5.0.out_layers.3.weight', 'output_blocks.5.0.skip_connection.bias', 'output_blocks.5.0.skip_connection.weight', 'output_blocks.5.1.norm.bias', 'output_blocks.5.1.norm.weight', 'output_blocks.5.1.proj_in.bias', 'output_blocks.5.1.proj_in.weight', 'output_blocks.5.1.proj_out.bias', 'output_blocks.5.1.proj_out.weight', 'output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'output_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'output_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'output_blocks.5.1.transformer_blocks.0.norm1.bias', 'output_blocks.5.1.transformer_blocks.0.norm1.weight', 'output_blocks.5.1.transformer_blocks.0.norm2.bias', 'output_blocks.5.1.transformer_blocks.0.norm2.weight', 'output_blocks.5.1.transformer_blocks.0.norm3.bias', 'output_blocks.5.1.transformer_blocks.0.norm3.weight', 'output_blocks.5.2.conv.bias', 'output_blocks.5.2.conv.weight', 'output_blocks.6.0.emb_layers.1.bias', 'output_blocks.6.0.emb_layers.1.weight', 'output_blocks.6.0.in_layers.0.bias', 'output_blocks.6.0.in_layers.0.weight', 'output_blocks.6.0.in_layers.2.bias', 'output_blocks.6.0.in_layers.2.weight', 'output_blocks.6.0.out_layers.0.bias', 'output_blocks.6.0.out_layers.0.weight', 'output_blocks.6.0.out_layers.3.bias', 'output_blocks.6.0.out_layers.3.weight', 'output_blocks.6.0.skip_connection.bias', 'output_blocks.6.0.skip_connection.weight', 'output_blocks.6.1.norm.bias', 'output_blocks.6.1.norm.weight', 'output_blocks.6.1.proj_in.bias', 'output_blocks.6.1.proj_in.weight', 'output_blocks.6.1.proj_out.bias', 'output_blocks.6.1.proj_out.weight', 'output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight', 'output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias', 'output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight', 'output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight', 'output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight', 'output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight', 'output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias', 'output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight', 'output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight', 'output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight', 'output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias', 'output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight', 'output_blocks.6.1.transformer_blocks.0.ff.net.2.bias', 'output_blocks.6.1.transformer_blocks.0.ff.net.2.weight', 'output_blocks.6.1.transformer_blocks.0.norm1.bias', 'output_blocks.6.1.transformer_blocks.0.norm1.weight', 'output_blocks.6.1.transformer_blocks.0.norm2.bias', 'output_blocks.6.1.transformer_blocks.0.norm2.weight', 'output_blocks.6.1.transformer_blocks.0.norm3.bias', 'output_blocks.6.1.transformer_blocks.0.norm3.weight', 'output_blocks.7.0.emb_layers.1.bias', 'output_blocks.7.0.emb_layers.1.weight', 'output_blocks.7.0.in_layers.0.bias', 'output_blocks.7.0.in_layers.0.weight', 'output_blocks.7.0.in_layers.2.bias', 'output_blocks.7.0.in_layers.2.weight', 'output_blocks.7.0.out_layers.0.bias', 'output_blocks.7.0.out_layers.0.weight', 'output_blocks.7.0.out_layers.3.bias', 'output_blocks.7.0.out_layers.3.weight', 'output_blocks.7.0.skip_connection.bias', 'output_blocks.7.0.skip_connection.weight', 'output_blocks.7.1.norm.bias', 'output_blocks.7.1.norm.weight', 'output_blocks.7.1.proj_in.bias', 'output_blocks.7.1.proj_in.weight', 'output_blocks.7.1.proj_out.bias', 'output_blocks.7.1.proj_out.weight', 'output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'output_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'output_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'output_blocks.7.1.transformer_blocks.0.norm1.bias', 'output_blocks.7.1.transformer_blocks.0.norm1.weight', 'output_blocks.7.1.transformer_blocks.0.norm2.bias', 'output_blocks.7.1.transformer_blocks.0.norm2.weight', 'output_blocks.7.1.transformer_blocks.0.norm3.bias', 'output_blocks.7.1.transformer_blocks.0.norm3.weight', 'output_blocks.8.0.emb_layers.1.bias', 'output_blocks.8.0.emb_layers.1.weight', 'output_blocks.8.0.in_layers.0.bias', 'output_blocks.8.0.in_layers.0.weight', 'output_blocks.8.0.in_layers.2.bias', 'output_blocks.8.0.in_layers.2.weight', 'output_blocks.8.0.out_layers.0.bias', 'output_blocks.8.0.out_layers.0.weight', 'output_blocks.8.0.out_layers.3.bias', 'output_blocks.8.0.out_layers.3.weight', 'output_blocks.8.0.skip_connection.bias', 'output_blocks.8.0.skip_connection.weight', 'output_blocks.8.1.norm.bias', 'output_blocks.8.1.norm.weight', 'output_blocks.8.1.proj_in.bias', 'output_blocks.8.1.proj_in.weight', 'output_blocks.8.1.proj_out.bias', 'output_blocks.8.1.proj_out.weight', 'output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'output_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'output_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'output_blocks.8.1.transformer_blocks.0.norm1.bias', 'output_blocks.8.1.transformer_blocks.0.norm1.weight', 'output_blocks.8.1.transformer_blocks.0.norm2.bias', 'output_blocks.8.1.transformer_blocks.0.norm2.weight', 'output_blocks.8.1.transformer_blocks.0.norm3.bias', 'output_blocks.8.1.transformer_blocks.0.norm3.weight', 'output_blocks.8.2.conv.bias', 'output_blocks.8.2.conv.weight', 'output_blocks.9.0.emb_layers.1.bias', 'output_blocks.9.0.emb_layers.1.weight', 'output_blocks.9.0.in_layers.0.bias', 'output_blocks.9.0.in_layers.0.weight', 'output_blocks.9.0.in_layers.2.bias', 'output_blocks.9.0.in_layers.2.weight', 'output_blocks.9.0.out_layers.0.bias', 'output_blocks.9.0.out_layers.0.weight', 'output_blocks.9.0.out_layers.3.bias', 'output_blocks.9.0.out_layers.3.weight', 'output_blocks.9.0.skip_connection.bias', 'output_blocks.9.0.skip_connection.weight', 'output_blocks.9.1.norm.bias', 'output_blocks.9.1.norm.weight', 'output_blocks.9.1.proj_in.bias', 'output_blocks.9.1.proj_in.weight', 'output_blocks.9.1.proj_out.bias', 'output_blocks.9.1.proj_out.weight', 'output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight', 'output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias', 'output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight', 'output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight', 'output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight', 'output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight', 'output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias', 'output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight', 'output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight', 'output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight', 'output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias', 'output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight', 'output_blocks.9.1.transformer_blocks.0.ff.net.2.bias', 'output_blocks.9.1.transformer_blocks.0.ff.net.2.weight', 'output_blocks.9.1.transformer_blocks.0.norm1.bias', 'output_blocks.9.1.transformer_blocks.0.norm1.weight', 'output_blocks.9.1.transformer_blocks.0.norm2.bias', 'output_blocks.9.1.transformer_blocks.0.norm2.weight', 'output_blocks.9.1.transformer_blocks.0.norm3.bias', 'output_blocks.9.1.transformer_blocks.0.norm3.weight', 'time_embed.0.bias', 'time_embed.0.weight', 'time_embed.2.bias', 'time_embed.2.weight']\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "from safetensors.torch import load_file\n",
    "device = \"cuda\"\n",
    "# Создаём pipeline и получаем UNet\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16, safety_checker=None,).to(\"cuda\")\n",
    "ckpt_path = \"C:/comfy/ComfyUI_windows_portable/ComfyUI/models/checkpoints/dreamshaper_8.safetensors\"   # или путь к SDXL\n",
    "unet = pipe.unet\n",
    "state_dict = load_file(ckpt_path)  # возвращает словарь {param_name: tensor}\n",
    "\n",
    "# Фильтруем и загружаем только веса UNet\n",
    "unet_keys = [k for k in state_dict.keys() if k.startswith(\"model.diffusion_model.\")]\n",
    "mapped_state_dict = {\n",
    "    k.replace(\"model.diffusion_model.\", \"\"): v for k, v in state_dict.items() if k.startswith(\"model.diffusion_model.\")\n",
    "}\n",
    "missing, unexpected = unet.load_state_dict(mapped_state_dict, strict=False)\n",
    "print(f\"Missing: {missing}, Unexpected: {unexpected}\")\n",
    "\n",
    "# Инициализируем модуль\n",
    "ip_adapter = IPAdapterModule(\n",
    "    image_encoder_path=\"laion/CLIP-ViT-H-14-laion2B-s32B-b79K\",\n",
    "    ip_ckpt=\"C:/comfy/ComfyUI_windows_portable/ComfyUI/models/ipadapter/ip-adapter_sd15.safetensors\",\n",
    "    device=\"cuda\",\n",
    "    num_tokens=4,\n",
    "    cross_attention_dim=768\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc419fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7899971bf4a4c59be7c8f3f7e1c9672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Применяем патч к UNet\n",
    "ip_adapter.set_ip_adapter(pipe.unet)\n",
    "\n",
    "# 4. Загрузка изображения для conditioning\n",
    "image_path = \"example.png\"  # путь к conditioning изображению\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# 5. Получаем image prompt embeddings\n",
    "image_prompt_embeds, uncond_image_prompt_embeds = ip_adapter.get_image_embeds(pil_image=image)\n",
    "\n",
    "# 6. Подготовка текстового промпта\n",
    "prompt = \"a majestic castle in the mountains at sunset,  \"\n",
    "negative_prompt = \"blurry, low quality\"\n",
    "\n",
    "# 7. Получаем текстовые эмбеддинги (вне @torch.inference_mode, если в train loop)\n",
    "with torch.no_grad():\n",
    "    prompt_embeds, negative_prompt_embeds = pipe.encode_prompt(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        device=device,\n",
    "        do_classifier_free_guidance=True,\n",
    "        num_images_per_prompt=1\n",
    "    )\n",
    "\n",
    "    # # 8. Объединяем текст и визуальные эмбеддинги\n",
    "    # prompt_embeds = torch.cat([prompt_embeds, image_prompt_embeds], dim=1)\n",
    "    # negative_prompt_embeds = torch.cat([negative_prompt_embeds, uncond_image_prompt_embeds], dim=1)\n",
    "\n",
    "# 9. Генерация изображения\n",
    "generator = torch.manual_seed(42)\n",
    "output = pipe(\n",
    "    prompt_embeds=prompt_embeds,\n",
    "    negative_prompt_embeds=negative_prompt_embeds,\n",
    "    guidance_scale=7.5,\n",
    "    num_inference_steps=30,\n",
    "    generator=generator\n",
    ")\n",
    "\n",
    "# 10. Сохраняем изображение\n",
    "output.images[0].save(\"generated_with_ip_adapter.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44444566",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_adapter.set_ip_adapter(unet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aca4beb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't connect to the Hub: (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /api/models/runwayml/stable-diffusion-v1-5 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001DF8008C050>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: ee3c77e8-2274-4225-bfe7-8a54e51be369)').\n",
      "Will try to load from local cache.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937ba90c9d814e5d85e03a27abf39099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)\n",
    "pipe = pipe.to(device)\n",
    "pipe.enable_attention_slicing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acfd887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = pipe.tokenizer\n",
    "text_encoder = pipe.text_encoder\n",
    "\n",
    "prompt = \"a majestic cat in a futuristic city\"\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=77)\n",
    "text_embed = text_encoder(tokens.input_ids.to(device))[0]  # shape: [1, 77, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a300d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_patch(block_to_conditioning: dict, weight: float = 1.0):\n",
    "    def attn_patch(attn_module, encoder_hidden_states, **kwargs):\n",
    "        # определяем, нужен ли патч\n",
    "        block_name = getattr(attn_module, \"block_name\", None)\n",
    "        if block_name not in block_to_conditioning:\n",
    "            return encoder_hidden_states\n",
    "\n",
    "        cond = block_to_conditioning[block_name]  # твой внешний conditioning\n",
    "        if cond.shape != encoder_hidden_states.shape:\n",
    "            raise ValueError(\"Shape mismatch in attention patch\")\n",
    "        \n",
    "        # смешиваем conditioning и оригинальный контекст\n",
    "        return (1 - weight) * encoder_hidden_states + weight * cond\n",
    "\n",
    "    return attn_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a55f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import MethodType\n",
    "\n",
    "def patch_unet_cross_attention(unet, conditioning, target_blocks=None, weight=1.0):\n",
    "    \"\"\"\n",
    "    Подменяет encoder_hidden_states в CrossAttention модулях UNet.\n",
    "    target_blocks — список имён модулей, которые мы хотим патчить, \n",
    "                    например [\"mid_block.attentions.0\", ...]. Если None — все.\n",
    "    \"\"\"\n",
    "    for name, module in unet.named_modules():\n",
    "        # патчим только CrossAttention\n",
    "        if not isinstance(module, CrossAttention):\n",
    "            continue\n",
    "        # если указан список блоков — фильтруем по нему\n",
    "        if target_blocks is not None:\n",
    "            if not any(name.startswith(tb) for tb in target_blocks):\n",
    "                continue\n",
    "\n",
    "        # сохраняем старый forward\n",
    "        old_forward = module.forward\n",
    "\n",
    "        def make_new_forward(old_fwd):\n",
    "            def new_forward(self, hidden_states, encoder_hidden_states=None, **kwargs):\n",
    "                # если есть encoder_hidden_states — смешиваем\n",
    "                if encoder_hidden_states is not None:\n",
    "                    # conditioning: [B, seq_len, D], encoder_hidden_states: same shape\n",
    "                    encoder_hidden_states = (\n",
    "                        (1 - weight) * encoder_hidden_states + weight * conditioning\n",
    "                    )\n",
    "                # вызываем оригинальный forward\n",
    "                return old_fwd(hidden_states, encoder_hidden_states=encoder_hidden_states, **kwargs)\n",
    "            return new_forward\n",
    "\n",
    "        # связываем новый метод\n",
    "        module.forward = MethodType(make_new_forward(old_forward), module)\n",
    "        print(f\"Patched CrossAttention at {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94bb34d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't connect to the Hub: (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /api/models/runwayml/stable-diffusion-v1-5 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E0596D6210>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: b931a02d-85b3-4f9d-88df-8ec056ce6774)').\n",
      "Will try to load from local cache.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9178dbfb080a4efd9ac2cd5be5e3c5ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patched CrossAttention at mid_block.attentions.0.transformer_blocks.0.attn1\n",
      "Patched CrossAttention at mid_block.attentions.0.transformer_blocks.0.attn2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef78adddc7d4f259852aacf6efd873f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Пример использования:\n",
    "device = torch.device(\"cuda\")\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16).to(device)\n",
    "pipe.enable_attention_slicing()\n",
    "\n",
    "# Получаем текстовый эмбеддинг\n",
    "tokenizer = pipe.tokenizer\n",
    "text_encoder = pipe.text_encoder\n",
    "prompt = \"an astronaut riding a horse, oil painting style\"\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=77)\n",
    "text_embed = text_encoder(tokens.input_ids.to(device))[0]  # [1, 77, 768]\n",
    "\n",
    "# Патчим только средний блок (можно указать несколько)\n",
    "patch_unet_cross_attention(\n",
    "    pipe.unet,\n",
    "    conditioning=text_embed,\n",
    "    target_blocks=[\"mid_block.attentions.0\"],\n",
    "    weight=1.0\n",
    ")\n",
    "\n",
    "# Генерация\n",
    "generator = torch.manual_seed(42)\n",
    "image = pipe(\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=30,\n",
    "    guidance_scale=7.5,\n",
    "    generator=generator\n",
    ").images[0]\n",
    "\n",
    "image.save(\"patched_output.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
